<<<<<<< HEAD
{"cells":[{"cell_type":"code","execution_count":null,"id":"c0bf904f","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c0bf904f","executionInfo":{"status":"ok","timestamp":1680150965238,"user_tz":-540,"elapsed":11972,"user":{"displayName":"지승영","userId":"07006377205744982370"}},"outputId":"0f0a49a9-3f28-471c-ece9-2cb6417c99f9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.27.4-py3-none-any.whl (6.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.7)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n","Collecting huggingface-hub<1.0,>=0.11.0\n","  Downloading huggingface_hub-0.13.3-py3-none-any.whl (199 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 KB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.13.3 tokenizers-0.13.2 transformers-4.27.4\n"]}],"source":["pip install transformers "]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gn4fxE6Ny6IX","executionInfo":{"status":"ok","timestamp":1680150941313,"user_tz":-540,"elapsed":32983,"user":{"displayName":"지승영","userId":"07006377205744982370"}},"outputId":"67056a80-0eeb-46df-c9ed-53179b5d698d"},"id":"Gn4fxE6Ny6IX","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import os\n","os.chdir('/content/drive/MyDrive/github/Dacon/chatgpt경진대회')\n","os.getcwd()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"R4fnj5Ycza1j","executionInfo":{"status":"ok","timestamp":1680154505094,"user_tz":-540,"elapsed":805,"user":{"displayName":"지승영","userId":"07006377205744982370"}},"outputId":"81fa9892-319c-43ea-abfa-6eb115787ef2"},"id":"R4fnj5Ycza1j","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/github/Dacon/chatgpt경진대회'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":1}]},{"cell_type":"markdown","source":["+ 프롬프트1\n","good!\n","I want to change model.\n","I want to use neural network model to predict news category by article.\n","Give me the sota model code for news category classification.\n","\n","use train.csv for model training and validation.\n","And make submission file 'submission_nnmodel.csv' from test.csv\n","\n","train epoch is 30 and metric is f1 score.\n","if there is no improvment until 10 epochs, then stop training and predict test label.\n","\n","+ 프롬프트2\n","good.\n","But you have to make submission_nnmodel.csv file from test.csv and your model.\n","And before make submission_nnmodel.csv file\n","train validation set to model\n","\n","\n","+ 프롬프트3\n","잘했어. 1개의 코드로 합쳐서 다시 적어줘\n","\n","+ 프롬프트4\n","답변이 짤리는데, 두 개로 나눠서 작성해줘\n","\n","+ 프롬프트5\n","part2가 잘렸어. \n","마저 작성해줘\n","\n"],"metadata":{"id":"wQAmqgJD204e"},"id":"wQAmqgJD204e"},{"cell_type":"code","source":["import pandas as pd\n","import torch\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import f1_score\n","from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, Trainer, TrainingArguments\n","\n","# Load the training data\n","train_data = pd.read_csv('train.csv')\n","\n","# Load the testing data\n","test_data = pd.read_csv('test.csv')\n","\n","# Split the training data into training and validation sets\n","X_train, X_val, y_train, y_val = train_test_split(train_data['text'], train_data['label'], test_size=0.2, random_state=42)\n","\n","# Encode the labels\n","label_encoder = LabelEncoder()\n","y_train_encoded = label_encoder.fit_transform(y_train)\n","y_val_encoded = label_encoder.transform(y_val)\n","\n","# Tokenize the text data\n","tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n","\n","train_encodings = tokenizer(X_train.tolist(), truncation=True, padding=True, max_length=512)\n","val_encodings = tokenizer(X_val.tolist(), truncation=True, padding=True, max_length=512)\n","\n","# Create a custom dataset class\n","class NewsDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        item['labels'] = torch.tensor(self.labels[idx])\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","# Create dataset objects for train and validation data\n","train_dataset = NewsDataset(train_encodings, y_train_encoded)\n","val_dataset = NewsDataset(val_encodings, y_val_encoded)\n","\n","# Compute the weighted F1 score metric\n","def compute_metrics(eval_pred):\n","    logits, labels = eval_pred\n","    predictions = np.argmax(logits, axis=-1)\n","    f1 = f1_score(labels, predictions, average='weighted')\n","    return {'f1': f1}\n","\n","# Training arguments\n","training_args = TrainingArguments(\n","    output_dir='./results',\n","    num_train_epochs=30,\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    logging_dir='./logs',\n","    logging_steps=50,\n","    save_steps=50,\n","    save_total_limit=1,\n","    load_best_model_at_end=True,\n","    metric_for_best_model='f1',\n","    evaluation_strategy='epoch',\n","    report_to='none',\n","    gradient_accumulation_steps=1,\n","    fp16=True,\n","    warmup_steps=50,\n","    weight_decay=0.01,\n","    adam_beta1=0.9,\n","    adam_beta2=0.999,\n","    adam_epsilon=1e-8,\n","    learning_rate=5e-5,\n","    early_stopping_patience=10\n",")\n","\n","# Initialize the model\n","num_labels = len(label_encoder.classes_)\n","model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=num_labels)\n","\n","# Create the Trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    compute_metrics=compute_metrics\n",")\n","\n","# Train the model\n","trainer.train()\n","\n","# Combine the training and validation sets for refitting\n","X_train_val = pd.concat([X_train, X_val])\n","y_train_val_encoded = label_encoder.transform(pd.concat([y_train, y_val]))\n","\n","\n","# Tokenize and create a dataset object for the combined data\n","train_val_encodings = tokenizer(X_train_val.tolist(), truncation=True, padding=True, max_length=512)\n","train_val_dataset = NewsDataset(train_val_encodings, y_train_val_encoded)\n","\n","# Update the training arguments for refitting\n","training_args.num_train_epochs = 5\n","trainer.args = training_args\n","trainer.train_dataset = train_val_dataset\n","\n","# Refit the model with the combined data\n","trainer.train()\n","\n","# Tokenize the test data\n","test_encodings = tokenizer(test_data['text'].tolist(), truncation=True, padding=True, max_length=512)\n","\n","# Create a dataset object for the test data without labels\n","test_dataset = NewsDataset(test_encodings, [0] * len(test_data))\n","\n","# Make predictions on the test set\n","test_predictions = trainer.predict(test_dataset).predictions\n","test_data['label'] = label_encoder.inverse_transform(np.argmax(test_predictions, axis=-1))\n","\n","# Save the submission file\n","submission = test_data[['id', 'label']]\n","submission.to_csv('submission_nnmodel.csv', index=False)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":379,"referenced_widgets":["d2235bc38f514c1ab3e6704c2826c609","942497cdbc6844039c99e844cbcb0427","0ddaf4e1dca24553926e6ad03b06205e","ab72dbfe3d36471383022d1936544705","4ea1ac624a0e4c7586480652dfe82d4c","6a772397970a4c669113e43b4669d73d","cd7abff733aa4cdfa1d83443fd59db0f","0d4b26fef0a441408ba66708047e2a26","5005d5d2a6f348398f37be5424aac3f2","3f985e100a7a493b9af0d96093776520","986ea41221de4d269ffbd030fbce82f3","229a9b4f7f1b481f99e50050172d6949","15e0011cc9f540f2ba0217f50602291d","750edc84afa74377bfc8ec3b59a42172","a9fe05ffd7f242079cc398f78b47a7b6","6b450b0338ba427181f64299f499e942","9f1cc170c7b84acea16123af070dae70","7c6f7269cdd3484799db806a536a767c","09073d7273824416a3b72837c418365e","cfc51cc99e6144e59546669724591f35","f859a752856d45d48bc418fcc33cc658","c45b2f865c144155a12bb1f0fa873414","a7ecf2d36f954f778d76e84bd3492ef6","cbf13baa3fad463e88e7fe637bc58ab9","ff509959530f4d5dbeaeef2c4be82c1d","0a079a37cb6241b798f211460e1e4a08","a810086781a842ae9050b535c4c6f565","3c10173d3b5c493d9833745ff25e0b48","ed13ab613f474b6da995d48629667b7e","5f168c47a21343a69b3f59cb0410d627","2ba7be9513da4891bf4e4d8894ed3b9d","ea918ef096304eae9f45244a63e433a2","a49ea5d722c64be68f1a8b5ac1368a9e","d54300b013b94d059a13780f1e0527e2","75efa1e9c70448ef94b08fde1011a921","c5d23b2f7b204ee9a00524e5c2d7b6f2","1b221b7cf81b4fdeaa0c87336a66a1ae","1f28e9cf30174dc691c41aa770045be7","b1dd1e720c5142dabfbc62d5768945f7","f0897ec014524f3fa09f56c35e765329","b4def8a04673453ca89e11e51b3ea2dd","f7e3a3a2a1184df2bf3f85cb6dc6169d","98a0706280994a649129db105365fe81","924cc3e09e2a4697aa7fc60737416d9d"]},"id":"ivsEgxDsy6m7","executionInfo":{"status":"error","timestamp":1680151936700,"user_tz":-540,"elapsed":148845,"user":{"displayName":"지승영","userId":"07006377205744982370"}},"outputId":"0e26e973-38ba-43d8-e250-ad631b852c2c"},"id":"ivsEgxDsy6m7","execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2235bc38f514c1ab3e6704c2826c609"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"229a9b4f7f1b481f99e50050172d6949"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a7ecf2d36f954f778d76e84bd3492ef6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d54300b013b94d059a13780f1e0527e2"}},"metadata":{}},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-f66b10d88305>\u001b[0m in \u001b[0;36m<cell line: 55>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;31m# Training arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m training_args = TrainingArguments(\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./results'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mnum_train_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'early_stopping_patience'"]}]},{"cell_type":"markdown","source":["\n","+ 프롬프트 6\n","I got an error. plz fix it and give me code again\n","\n","     54 # Training arguments\n","---> 55 training_args = TrainingArguments(\n","     56     output_dir='./results',\n","     57     num_train_epochs=30,\n","\n","TypeError: __init__() got an unexpected keyword argument 'early_stopping_patience'\n","\n","+ 프롬프트 7\n","\n","이어서 마저 작성해줘"],"metadata":{"id":"a3EC4yK13r7C"},"id":"a3EC4yK13r7C"},{"cell_type":"code","source":["import pandas as pd\n","import torch\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import f1_score\n","from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, Trainer, TrainingArguments\n","from transformers.trainer_callback import EarlyStoppingCallback\n","\n","# Load the training data\n","train_data = pd.read_csv('train.csv')\n","\n","# Load the testing data\n","test_data = pd.read_csv('test.csv')\n","\n","# Split the training data into training and validation sets\n","X_train, X_val, y_train, y_val = train_test_split(train_data['text'], train_data['label'], test_size=0.2, random_state=42)\n","\n","# Encode the labels\n","label_encoder = LabelEncoder()\n","y_train_encoded = label_encoder.fit_transform(y_train)\n","y_val_encoded = label_encoder.transform(y_val)\n","\n","# Tokenize the text data\n","tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n","\n","train_encodings = tokenizer(X_train.tolist(), truncation=True, padding=True, max_length=512)\n","val_encodings = tokenizer(X_val.tolist(), truncation=True, padding=True, max_length=512)\n","\n","# Create a custom dataset class\n","class NewsDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        item['labels'] = torch.tensor(self.labels[idx])\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","# Create dataset objects for train and validation data\n","train_dataset = NewsDataset(train_encodings, y_train_encoded)\n","val_dataset = NewsDataset(val_encodings, y_val_encoded)\n","\n","# Compute the weighted F1 score metric\n","def compute_metrics(eval_pred):\n","    logits, labels = eval_pred\n","    predictions = np.argmax(logits, axis=-1)\n","    f1 = f1_score(labels, predictions, average='weighted')\n","    return {'f1': f1}\n","\n","# Training arguments\n","training_args = TrainingArguments(\n","    output_dir='./results',\n","    num_train_epochs=30,\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    logging_dir='./logs',\n","    logging_steps=50,\n","    save_steps=50,\n","    save_total_limit=1,\n","    load_best_model_at_end=True,\n","    metric_for_best_model='f1',\n","    evaluation_strategy='epoch',\n","    report_to='none',\n","    gradient_accumulation_steps=1,\n","    fp16=True,\n","    warmup_steps=50,\n","    weight_decay=0.01,\n","    adam_beta1=0.9,\n","    adam_beta2=0.999,\n","    adam_epsilon=1e-8,\n","    learning_rate=5e-5,\n",")\n","\n","# Initialize the model\n","num_labels = len(label_encoder.classes_)\n","model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=num_labels)\n","\n","# Create the Trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    compute_metrics=compute_metrics,\n","    callbacks=[EarlyStoppingCallback(patience=10)]\n",")\n","\n","# Train the model\n","trainer.train()\n","\n","# Combine the training and validation sets for refitting\n","X_train_val = pd.concat([X_train, X_val])\n","y_train_val_encoded = label_encoder.transform(pd.concat([y_train, y_val]))\n","\n","# Tokenize and create a dataset object for the combined data\n","train_val_encodings = tokenizer(X_train_val.tolist(), truncation=True, padding=True, max_length=512)\n","train_val_dataset = NewsDataset(train_val_encodings, y_train_val_encoded)\n","\n","# Update the training arguments for refitting\n","training_args.num_train_epochs = 5\n","trainer.args = training_args\n","trainer.train_dataset = train_val_dataset\n","\n","# Refit the model with the combined data\n","trainer.train()\n","\n","# Tokenize the test data\n","test_encodings = tokenizer(test_data['text'].tolist(), truncation=True, padding=True, max_length=512)\n","\n","# Create a dataset object for the test data without labels\n","test_dataset = NewsDataset(test_encodings, [0] * len(test_data))\n","\n","# Make predictions on the test set\n","test_predictions = trainer.predict(test_dataset).predictions\n","test_data['label'] = label_encoder.inverse_transform(np.argmax(test_predictions, axis=-1))\n","\n","# Save the submission file\n","submission = test_data[['id', 'label']]\n","submission.to_csv('submission_nnmodel.csv', index=False)\n"],"metadata":{"id":"aT8LSLabzOkJ"},"id":"aT8LSLabzOkJ","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Jey_UQzb3zE4"},"id":"Jey_UQzb3zE4","execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import torch\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import f1_score\n","from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, Trainer, TrainingArguments\n","from transformers.trainer_callback import EarlyStoppingCallback\n","\n","# Load the training data\n","train_data = pd.read_csv('train.csv')\n","\n","# Load the testing data\n","test_data = pd.read_csv('test.csv')\n","\n","# Split the training data into training and validation sets\n","X_train, X_val, y_train, y_val = train_test_split(train_data['text'], train_data['label'], test_size=0.2, random_state=42)\n","\n","# Encode the labels\n","label_encoder = LabelEncoder()\n","y_train_encoded = label_encoder.fit_transform(y_train)\n","y_val_encoded = label_encoder.transform(y_val)\n","\n","# Tokenize the text data\n","tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n","\n","train_encodings = tokenizer(X_train.tolist(), truncation=True, padding=True, max_length=256)\n","val_encodings = tokenizer(X_val.tolist(), truncation=True, padding=True, max_length=256)\n","\n","# Create a custom dataset class\n","class NewsDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        item['labels'] = torch.tensor(self.labels[idx])\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","# Create dataset objects for train and validation data\n","train_dataset = NewsDataset(train_encodings, y_train_encoded)\n","val_dataset = NewsDataset(val_encodings, y_val_encoded)\n","\n","# Compute the weighted F1 score metric\n","def compute_metrics(eval_pred):\n","    logits, labels = eval_pred\n","    predictions = np.argmax(logits, axis=-1)\n","    f1 = f1_score(labels, predictions, average='weighted')\n","    return {'f1': f1}\n","\n","# Training arguments\n","training_args = TrainingArguments(\n","    output_dir='./results',\n","    num_train_epochs=30,\n","    per_device_train_batch_size=4,\n","    per_device_eval_batch_size=4,\n","    logging_dir='./logs',\n","    logging_steps=50,\n","    save_steps=50,\n","    save_total_limit=1,\n","    load_best_model_at_end=True,\n","    metric_for_best_model='f1',\n","    evaluation_strategy='epoch',\n","    report_to='none',\n","    gradient_accumulation_steps=1,\n","    fp16=True,\n","    warmup_steps=50,\n","    weight_decay=0.01,\n","    adam_beta1=0.9,\n","    adam_beta2=0.999,\n","    adam_epsilon=1e-8,\n","    learning_rate=5e-5,\n",")\n","\n","# Initialize the model\n","num_labels = len(label_encoder.classes_)\n","model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=num_labels)\n","\n","# Create the Trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    compute_metrics=compute_metrics,\n","    callbacks=[EarlyStoppingCallback(patience=10)]\n",")\n","\n","# Train the model\n","trainer.train()\n","\n","# Combine the training and validation sets for refitting\n","# Combine the training and validation sets for refitting\n","X_train_val = pd.concat([X_train, X_val])\n","y_train_val_encoded = label_encoder.transform(pd.concat([y_train, y_val]))\n","\n","# Tokenize and create a dataset object for the combined data\n","train_val_encodings = tokenizer(X_train_val.tolist(), truncation=True, padding=True, max_length=256)\n","train_val_dataset = NewsDataset(train_val_encodings, y_train_val_encoded)\n","\n","# Update the training arguments for refitting\n","training_args.num_train_epochs = 5\n","trainer.args = training_args\n","trainer.train_dataset = train_val_dataset\n","\n","# Refit the model with the combined data\n","trainer.train()\n","\n","# Tokenize the test data\n","test_encodings = tokenizer(test_data['text'].tolist(), truncation=True, padding=True, max_length=256)\n","\n","# Create a dataset object for the test data without labels\n","test_dataset = NewsDataset(test_encodings, [0] * len(test_data))\n","\n","# Make predictions on the test set\n","test_predictions = trainer.predict(test_dataset).predictions\n","test_data['label'] = label_encoder.inverse_transform(np.argmax(test_predictions, axis=-1))\n","\n","# Save the submission file\n","submission = test_data[['id', 'label']]\n","submission.to_csv('submission_nnmodel.csv', index=False)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":461},"id":"2oKKBjXF44Ma","executionInfo":{"status":"error","timestamp":1680152588491,"user_tz":-540,"elapsed":91476,"user":{"displayName":"지승영","userId":"07006377205744982370"}},"outputId":"b530c729-fb69-486c-f2dc-5367a22f3794"},"id":"2oKKBjXF44Ma","execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-153d14f3d04c>\u001b[0m in \u001b[0;36m<cell line: 56>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;31m# Training arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m training_args = TrainingArguments(\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./results'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mnum_train_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/training_args.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, output_dir, overwrite_output_dir, do_train, do_eval, do_predict, evaluation_strategy, prediction_loss_only, per_device_train_batch_size, per_device_eval_batch_size, per_gpu_train_batch_size, per_gpu_eval_batch_size, gradient_accumulation_steps, eval_accumulation_steps, eval_delay, learning_rate, weight_decay, adam_beta1, adam_beta2, adam_epsilon, max_grad_norm, num_train_epochs, max_steps, lr_scheduler_type, warmup_ratio, warmup_steps, log_level, log_level_replica, log_on_each_node, logging_dir, logging_strategy, logging_first_step, logging_steps, logging_nan_inf_filter, save_strategy, save_steps, save_total_limit, save_on_each_node, no_cuda, use_mps_device, seed, data_seed, jit_mode_eval, use_ipex, bf16, fp16, fp16_opt_level, half_precision_backend, bf16_full_eval, fp16_full_eval, tf32, local_rank, xpu_backend, tpu_num_cores, tpu_metrics_debug, debug, dataloader_drop_last, eval_steps, dataloader_num_workers, past_index, run_name, disable_tqdm, remove_unused_columns, label_names, load_best_model_at_end, metric_for_best_model, greater_is_better, ignore_data_skip, sharded_ddp, fsdp, fsdp_min_num_params, fsdp_config, fsdp_transformer_layer_cls_to_wrap, deepspeed, label_smoothing_factor, optim, optim_args, adafactor, group_by_length, length_column_name, report_to, ddp_find_unused_parameters, ddp_bucket_cap_mb, dataloader_pin_memory, skip_memory_metrics, use_legacy_pr...\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/training_args.py\u001b[0m in \u001b[0;36m__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1157\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_best_model_at_end\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_strategy\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_strategy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1159\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m   1160\u001b[0m                     \u001b[0;34m\"--load_best_model_at_end requires the save and eval strategy to match, but found\\n- Evaluation \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m                     \u001b[0;34mf\"strategy: {self.evaluation_strategy}\\n- Save strategy: {self.save_strategy}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: --load_best_model_at_end requires the save and eval strategy to match, but found\n- Evaluation strategy: epoch\n- Save strategy: steps"]}]},{"cell_type":"code","source":["import pandas as pd\n","import torch\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import f1_score\n","from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, Trainer, TrainingArguments\n","from transformers.trainer_callback import EarlyStoppingCallback\n","\n","# Load the training data\n","train_data = pd.read_csv('train.csv')\n","\n","# Load the testing data\n","test_data = pd.read_csv('test.csv')\n","\n","# Split the training data into training and validation sets\n","X_train, X_val, y_train, y_val = train_test_split(train_data['text'], train_data['label'], test_size=0.2, random_state=42)\n","\n","# Encode the labels\n","label_encoder = LabelEncoder()\n","y_train_encoded = label_encoder.fit_transform(y_train)\n","y_val_encoded = label_encoder.transform(y_val)\n","\n","# Tokenize the text data\n","tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n","\n","train_encodings = tokenizer(X_train.tolist(), truncation=True, padding=True, max_length=256)\n","val_encodings = tokenizer(X_val.tolist(), truncation=True, padding=True, max_length=256)\n","\n","# Create a custom dataset class\n","class NewsDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        item['labels'] = torch.tensor(self.labels[idx])\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","# Create dataset objects for train and validation data\n","train_dataset = NewsDataset(train_encodings, y_train_encoded)\n","val_dataset = NewsDataset(val_encodings, y_val_encoded)\n","\n","# Compute the weighted F1 score metric\n","def compute_metrics(eval_pred):\n","    logits, labels = eval_pred\n","    predictions = np.argmax(logits, axis=-1)\n","    f1 = f1_score(labels, predictions, average='weighted')\n","    return {'f1': f1}\n","\n","# Training arguments\n","training_args = TrainingArguments(\n","    output_dir='./results',\n","    num_train_epochs=30,\n","    per_device_train_batch_size=4,\n","    per_device_eval_batch_size=4,\n","    logging_dir='./logs',\n","    logging_steps=50,\n","    save_steps=50,\n","    save_total_limit=1,\n","    load_best_model_at_end=True,\n","    metric_for_best_model='f1',\n","    evaluation_strategy='epoch',\n","    report_to='none',\n","    gradient_accumulation_steps=1,\n","    fp16=True,\n","    warmup_steps=50,\n","    weight_decay=0.01,\n","    adam_beta1=0.9,\n","    adam_beta2=0.999,\n","    adam_epsilon=1e-8,\n","    learning_rate=5e-5,\n",")\n","\n","\n","# Initialize the model\n","num_labels = len(label_encoder.classes_)\n","model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=num_labels)\n","\n","# Create the Trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    compute_metrics=compute_metrics,\n","    callbacks=[EarlyStoppingCallback(patience=10)]\n",")\n","\n","# Train the model\n","trainer.train()\n","\n","# Combine the training and validation sets for refitting\n","X_train_val = pd.concat([X_train, X_val])\n","y_train_val_encoded = label_encoder.transform(pd.concat([y_train, y_val]))\n","\n","# Tokenize and create a dataset object for the combined data\n","train_val_encodings = tokenizer(X_train_val.tolist(), truncation=True, padding=True, max_length=256)\n","train_val_dataset = NewsDataset(train_val_encodings, y_train_val_encoded)\n","\n","# Update the training arguments for refitting\n","training_args.num_train_epochs = 5\n","training_args.save_strategy = 'epoch'  # Set save_strategy to match evaluation_strategy\n","trainer.args = training_args\n","trainer.train_dataset = train_val_dataset\n","\n","# Refit the model with the combined data\n","trainer.train()\n","\n","# Tokenize the test data\n","test_encodings = tokenizer(test_data['text'].tolist(), truncation=True, padding=True, max_length=256)\n","\n","# Create a dataset object for the test data without labels\n","test_dataset = NewsDataset(test_encodings, [0] * len(test_data))\n","\n","# Make predictions on the test set\n","test_predictions = trainer.predict(test_dataset).predictions\n","test_data['label'] = label_encoder.inverse_transform(np.argmax(test_predictions, axis=-1))\n","\n","# Save the submission file\n","submission = test_data[['id', 'label']]\n","submission.to_csv('submission_nnmodel.csv', index=False)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":461},"id":"XbmjThbA47YW","executionInfo":{"status":"error","timestamp":1680154277470,"user_tz":-540,"elapsed":97409,"user":{"displayName":"지승영","userId":"07006377205744982370"}},"outputId":"1b767271-9c36-4c26-b13d-bad5d1b65c68"},"id":"XbmjThbA47YW","execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-2f47557e4d3d>\u001b[0m in \u001b[0;36m<cell line: 56>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;31m# Training arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m training_args = TrainingArguments(\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./results'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mnum_train_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/training_args.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, output_dir, overwrite_output_dir, do_train, do_eval, do_predict, evaluation_strategy, prediction_loss_only, per_device_train_batch_size, per_device_eval_batch_size, per_gpu_train_batch_size, per_gpu_eval_batch_size, gradient_accumulation_steps, eval_accumulation_steps, eval_delay, learning_rate, weight_decay, adam_beta1, adam_beta2, adam_epsilon, max_grad_norm, num_train_epochs, max_steps, lr_scheduler_type, warmup_ratio, warmup_steps, log_level, log_level_replica, log_on_each_node, logging_dir, logging_strategy, logging_first_step, logging_steps, logging_nan_inf_filter, save_strategy, save_steps, save_total_limit, save_on_each_node, no_cuda, use_mps_device, seed, data_seed, jit_mode_eval, use_ipex, bf16, fp16, fp16_opt_level, half_precision_backend, bf16_full_eval, fp16_full_eval, tf32, local_rank, xpu_backend, tpu_num_cores, tpu_metrics_debug, debug, dataloader_drop_last, eval_steps, dataloader_num_workers, past_index, run_name, disable_tqdm, remove_unused_columns, label_names, load_best_model_at_end, metric_for_best_model, greater_is_better, ignore_data_skip, sharded_ddp, fsdp, fsdp_min_num_params, fsdp_config, fsdp_transformer_layer_cls_to_wrap, deepspeed, label_smoothing_factor, optim, optim_args, adafactor, group_by_length, length_column_name, report_to, ddp_find_unused_parameters, ddp_bucket_cap_mb, dataloader_pin_memory, skip_memory_metrics, use_legacy_pr...\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/training_args.py\u001b[0m in \u001b[0;36m__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1157\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_best_model_at_end\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_strategy\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_strategy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1159\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m   1160\u001b[0m                     \u001b[0;34m\"--load_best_model_at_end requires the save and eval strategy to match, but found\\n- Evaluation \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m                     \u001b[0;34mf\"strategy: {self.evaluation_strategy}\\n- Save strategy: {self.save_strategy}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: --load_best_model_at_end requires the save and eval strategy to match, but found\n- Evaluation strategy: epoch\n- Save strategy: steps"]}]},{"cell_type":"markdown","source":["I want to use other Neural Network model.\n","I want much shorter code.\n","please give me a python code."],"metadata":{"id":"0X_3OxzjAk-I"},"id":"0X_3OxzjAk-I"},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","# Load the data\n","train_data = pd.read_csv('train.csv')\n","test_data = pd.read_csv('test.csv')\n","\n","# Split the training data into training and validation sets\n","X_train, X_val, y_train, y_val = train_test_split(train_data['text'], train_data['label'], test_size=0.2, random_state=42)\n","\n","# Encode the labels\n","label_encoder = LabelEncoder()\n","y_train_encoded = label_encoder.fit_transform(y_train)\n","y_val_encoded = label_encoder.transform(y_val)\n","\n","# Tokenize the text data\n","max_features = 10000\n","max_len = 256\n","tokenizer = Tokenizer(num_words=max_features, oov_token='<OOV>')\n","tokenizer.fit_on_texts(X_train)\n","\n","X_train_sequences = tokenizer.texts_to_sequences(X_train)\n","X_val_sequences = tokenizer.texts_to_sequences(X_val)\n","X_train_padded = pad_sequences(X_train_sequences, maxlen=max_len, padding='post', truncating='post')\n","X_val_padded = pad_sequences(X_val_sequences, maxlen=max_len, padding='post', truncating='post')\n","\n","# Define the neural network model\n","model = Sequential([\n","    Embedding(max_features, 128, input_length=max_len),\n","    LSTM(64, return_sequences=True),\n","    Dropout(0.2),\n","    LSTM(32),\n","    Dense(8, activation='softmax')\n","])\n","\n","# Compile and train the model\n","model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","early_stop = EarlyStopping(monitor='val_loss', patience=10)\n","model.fit(X_train_padded, y_train_encoded, epochs=30, validation_data=(X_val_padded, y_val_encoded), callbacks=[early_stop])\n","\n","# Refit the model with the combined data\n","X_train_val = pd.concat([X_train, X_val])\n","y_train_val_encoded = label_encoder.transform(pd.concat([y_train, y_val]))\n","\n","X_train_val_sequences = tokenizer.texts_to_sequences(X_train_val)\n","X_train_val_padded = pad_sequences(X_train_val_sequences, maxlen=max_len, padding='post', truncating='post')\n","model.fit(X_train_val_padded, y_train_val_encoded, epochs=5)\n","\n","# Prepare the test data\n","test_sequences = tokenizer.texts_to_sequences(test_data['text'])\n","test_padded = pad_sequences(test_sequences, maxlen=max_len, padding='post', truncating='post')\n","\n","# Make predictions on the test set\n","test_predictions = np.argmax(model.predict(test_padded), axis=-1)\n","test_data['label'] = label_encoder.inverse_transform(test_predictions)\n","\n","# Save the submission file\n","submission = test_data[['id', 'label']]\n","submission.to_csv('submission_nnmodel.csv', index=False)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"86HN91ze-6tH","executionInfo":{"status":"ok","timestamp":1680155385417,"user_tz":-540,"elapsed":873754,"user":{"displayName":"지승영","userId":"07006377205744982370"}},"outputId":"80b35941-4012-47bc-e99c-e5e4f188fa53"},"id":"86HN91ze-6tH","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","1185/1185 [==============================] - 126s 98ms/step - loss: 1.0889 - accuracy: 0.5649 - val_loss: 0.7338 - val_accuracy: 0.7637\n","Epoch 2/30\n","1185/1185 [==============================] - 44s 37ms/step - loss: 1.0432 - accuracy: 0.6109 - val_loss: 1.1151 - val_accuracy: 0.5697\n","Epoch 3/30\n","1185/1185 [==============================] - 33s 28ms/step - loss: 0.8459 - accuracy: 0.6988 - val_loss: 0.6683 - val_accuracy: 0.7907\n","Epoch 4/30\n","1185/1185 [==============================] - 29s 25ms/step - loss: 0.5323 - accuracy: 0.8327 - val_loss: 0.5386 - val_accuracy: 0.8215\n","Epoch 5/30\n","1185/1185 [==============================] - 28s 24ms/step - loss: 0.4181 - accuracy: 0.8683 - val_loss: 0.4732 - val_accuracy: 0.8437\n","Epoch 6/30\n","1185/1185 [==============================] - 27s 22ms/step - loss: 0.3515 - accuracy: 0.8891 - val_loss: 0.4902 - val_accuracy: 0.8374\n","Epoch 7/30\n","1185/1185 [==============================] - 28s 24ms/step - loss: 0.2911 - accuracy: 0.9075 - val_loss: 0.5007 - val_accuracy: 0.8423\n","Epoch 8/30\n","1185/1185 [==============================] - 25s 21ms/step - loss: 0.2345 - accuracy: 0.9273 - val_loss: 0.4791 - val_accuracy: 0.8533\n","Epoch 9/30\n","1185/1185 [==============================] - 25s 21ms/step - loss: 0.1721 - accuracy: 0.9487 - val_loss: 0.4922 - val_accuracy: 0.8542\n","Epoch 10/30\n","1185/1185 [==============================] - 27s 23ms/step - loss: 0.1411 - accuracy: 0.9586 - val_loss: 0.5216 - val_accuracy: 0.8533\n","Epoch 11/30\n","1185/1185 [==============================] - 25s 21ms/step - loss: 0.1050 - accuracy: 0.9696 - val_loss: 0.5771 - val_accuracy: 0.8526\n","Epoch 12/30\n","1185/1185 [==============================] - 24s 20ms/step - loss: 0.0897 - accuracy: 0.9743 - val_loss: 0.5938 - val_accuracy: 0.8517\n","Epoch 13/30\n","1185/1185 [==============================] - 25s 21ms/step - loss: 0.0792 - accuracy: 0.9777 - val_loss: 0.6085 - val_accuracy: 0.8526\n","Epoch 14/30\n","1185/1185 [==============================] - 25s 21ms/step - loss: 0.0653 - accuracy: 0.9820 - val_loss: 0.6441 - val_accuracy: 0.8517\n","Epoch 15/30\n","1185/1185 [==============================] - 24s 20ms/step - loss: 0.0494 - accuracy: 0.9874 - val_loss: 0.6591 - val_accuracy: 0.8513\n","Epoch 1/5\n","1482/1482 [==============================] - 30s 20ms/step - loss: 0.1515 - accuracy: 0.9588\n","Epoch 2/5\n","1482/1482 [==============================] - 28s 19ms/step - loss: 0.0891 - accuracy: 0.9765\n","Epoch 3/5\n","1482/1482 [==============================] - 28s 19ms/step - loss: 0.0646 - accuracy: 0.9832\n","Epoch 4/5\n","1482/1482 [==============================] - 26s 18ms/step - loss: 0.0509 - accuracy: 0.9872\n","Epoch 5/5\n","1482/1482 [==============================] - 27s 19ms/step - loss: 0.0415 - accuracy: 0.9895\n","2605/2605 [==============================] - 22s 8ms/step\n"]}]},{"cell_type":"markdown","source":["Good. But I want to use f1 score as metric.\n","And change submission file name to 'submisson_nn_model2.csv'\n","\n","그래. f1 score를 model complie에 이용하는 방식으로, 코드 다시 짜줘"],"metadata":{"id":"FgxEWjKtE4hC"},"id":"FgxEWjKtE4hC"},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","# Custom F1 score metric function\n","def f1_metric(y_true, y_pred):\n","    true_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_true * y_pred, 0, 1)))\n","    possible_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_true, 0, 1)))\n","    predicted_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_pred, 0, 1)))\n","    precision = true_positives / (predicted_positives + tf.keras.backend.epsilon())\n","    recall = true_positives / (possible_positives + tf.keras.backend.epsilon())\n","    f1_val = 2 * (precision * recall) / (precision + recall + tf.keras.backend.epsilon())\n","    return f1_val\n","\n","# Load the data\n","train_data = pd.read_csv('train.csv')\n","test_data = pd.read_csv('test.csv')\n","\n","# Split the training data into training and validation sets\n","X_train, X_val, y_train, y_val = train_test_split(train_data['text'], train_data['label'], test_size=0.2, random_state=42)\n","\n","# Encode the labels\n","label_encoder = LabelEncoder()\n","y_train_encoded = label_encoder.fit_transform(y_train)\n","y_val_encoded = label_encoder.transform(y_val)\n","\n","# Tokenize the text data\n","max_features = 10000\n","max_len = 256\n","tokenizer = Tokenizer(num_words=max_features, oov_token='<OOV>')\n","tokenizer.fit_on_texts(X_train)\n","\n","X_train_sequences = tokenizer.texts_to_sequences(X_train)\n","X_val_sequences = tokenizer.texts_to_sequences(X_val)\n","X_train_padded = pad_sequences(X_train_sequences, maxlen=max_len, padding='post', truncating='post')\n","X_val_padded = pad_sequences(X_val_sequences, maxlen=max_len, padding='post', truncating='post')\n","\n","# Define the neural network model\n","model = Sequential([\n","    Embedding(max_features, 128, input_length=max_len),\n","    LSTM(64, return_sequences=True),\n","    Dropout(0.2),\n","    LSTM(32),\n","    Dense(8, activation='softmax')\n","])\n","\n","# Compile and train the model\n","model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy', f1_metric])\n","early_stop = EarlyStopping(monitor='val_loss', patience=10)\n","history = model.fit(X_train_padded, y_train_encoded, epochs=30, validation_data=(X_val_padded, y_val_encoded), callbacks=[early_stop])\n","\n","# Refit the model with the combined data\n","X_train_val = pd.concat([X_train, X_val])\n","y_train_val_encoded = label_encoder.transform(pd.concat([y_train, y_val]))\n","\n","X_train_val_sequences = tokenizer.texts_to_sequences(X_train_val)\n","X_train_val_padded = pad_sequences(X_train_val_sequences, maxlen=max_len, padding='post', truncating='post')\n","model.fit(X_train_val_padded, y_train_val_encoded, epochs=5)\n","\n","# Prepare the test data\n","test_sequences = tokenizer.texts_to_sequences(test_data['text'])\n","test_padded = pad_sequences(test_sequences, maxlen=max_len, padding='post', truncating='post')\n","\n","# Make predictions on the test set\n","test_predictions = np.argmax(model.predict(test_padded), axis=-1)\n","\n","# Decode the predicted labels\n","test_labels_pred = label_encoder.inverse_transform(test_predictions)\n","\n","# Create a submission file\n","submission = pd.DataFrame({'id': test_data['id'], 'label': test_labels_pred})\n","submission.to_csv('submission_nn_model2.csv', index=False)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RenysmlPAkfp","executionInfo":{"status":"ok","timestamp":1680156909226,"user_tz":-540,"elapsed":791815,"user":{"displayName":"지승영","userId":"07006377205744982370"}},"outputId":"0875d32e-4a66-4521-9c4f-97a15d51ae26"},"id":"RenysmlPAkfp","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","1185/1185 [==============================] - 92s 74ms/step - loss: 1.2627 - accuracy: 0.4376 - f1_metric: 2.7133 - val_loss: 1.0581 - val_accuracy: 0.5194 - val_f1_metric: 1.8850\n","Epoch 2/30\n","1185/1185 [==============================] - 36s 31ms/step - loss: 0.9070 - accuracy: 0.5859 - f1_metric: 1.5278 - val_loss: 0.8332 - val_accuracy: 0.6670 - val_f1_metric: 1.3842\n","Epoch 3/30\n","1185/1185 [==============================] - 30s 26ms/step - loss: 0.6516 - accuracy: 0.7754 - f1_metric: 1.0741 - val_loss: 0.6087 - val_accuracy: 0.7863 - val_f1_metric: 1.0477\n","Epoch 4/30\n","1185/1185 [==============================] - 27s 23ms/step - loss: 0.4615 - accuracy: 0.8468 - f1_metric: 0.9758 - val_loss: 0.5074 - val_accuracy: 0.8300 - val_f1_metric: 0.9537\n","Epoch 5/30\n","1185/1185 [==============================] - 28s 24ms/step - loss: 0.3754 - accuracy: 0.8768 - f1_metric: 0.9587 - val_loss: 0.4712 - val_accuracy: 0.8405 - val_f1_metric: 0.9698\n","Epoch 6/30\n","1185/1185 [==============================] - 26s 22ms/step - loss: 0.3175 - accuracy: 0.8961 - f1_metric: 0.9411 - val_loss: 0.4654 - val_accuracy: 0.8463 - val_f1_metric: 0.9375\n","Epoch 7/30\n","1185/1185 [==============================] - 26s 22ms/step - loss: 0.2692 - accuracy: 0.9126 - f1_metric: 0.9286 - val_loss: 0.4794 - val_accuracy: 0.8484 - val_f1_metric: 0.9430\n","Epoch 8/30\n","1185/1185 [==============================] - 26s 22ms/step - loss: 0.2233 - accuracy: 0.9277 - f1_metric: 0.9240 - val_loss: 0.4755 - val_accuracy: 0.8550 - val_f1_metric: 0.9438\n","Epoch 9/30\n","1185/1185 [==============================] - 25s 21ms/step - loss: 0.1630 - accuracy: 0.9499 - f1_metric: 0.8933 - val_loss: 0.4698 - val_accuracy: 0.8569 - val_f1_metric: 0.9155\n","Epoch 10/30\n","1185/1185 [==============================] - 27s 23ms/step - loss: 0.1334 - accuracy: 0.9603 - f1_metric: 0.8788 - val_loss: 0.4827 - val_accuracy: 0.8654 - val_f1_metric: 0.9004\n","Epoch 11/30\n","1185/1185 [==============================] - 25s 21ms/step - loss: 0.1004 - accuracy: 0.9713 - f1_metric: 0.8642 - val_loss: 0.4857 - val_accuracy: 0.8639 - val_f1_metric: 0.8951\n","Epoch 12/30\n","1185/1185 [==============================] - 26s 22ms/step - loss: 0.0828 - accuracy: 0.9771 - f1_metric: 0.8554 - val_loss: 0.5604 - val_accuracy: 0.8566 - val_f1_metric: 0.8840\n","Epoch 13/30\n","1185/1185 [==============================] - 25s 21ms/step - loss: 0.0670 - accuracy: 0.9822 - f1_metric: 0.8477 - val_loss: 0.5728 - val_accuracy: 0.8591 - val_f1_metric: 0.8687\n","Epoch 14/30\n","1185/1185 [==============================] - 24s 20ms/step - loss: 0.0546 - accuracy: 0.9862 - f1_metric: 0.8402 - val_loss: 0.6189 - val_accuracy: 0.8582 - val_f1_metric: 0.8698\n","Epoch 15/30\n","1185/1185 [==============================] - 25s 21ms/step - loss: 0.0493 - accuracy: 0.9873 - f1_metric: 0.8396 - val_loss: 0.6033 - val_accuracy: 0.8615 - val_f1_metric: 0.8651\n","Epoch 16/30\n","1185/1185 [==============================] - 27s 23ms/step - loss: 0.0391 - accuracy: 0.9900 - f1_metric: 0.8348 - val_loss: 0.6688 - val_accuracy: 0.8600 - val_f1_metric: 0.8587\n","Epoch 1/5\n","1482/1482 [==============================] - 28s 19ms/step - loss: 0.1376 - accuracy: 0.9628 - f1_metric: 0.8574\n","Epoch 2/5\n","1482/1482 [==============================] - 28s 19ms/step - loss: 0.0792 - accuracy: 0.9804 - f1_metric: 0.8421\n","Epoch 3/5\n","1482/1482 [==============================] - 27s 18ms/step - loss: 0.0573 - accuracy: 0.9858 - f1_metric: 0.8382\n","Epoch 4/5\n","1482/1482 [==============================] - 30s 20ms/step - loss: 0.0438 - accuracy: 0.9891 - f1_metric: 0.8334\n","Epoch 5/5\n","1482/1482 [==============================] - 27s 18ms/step - loss: 0.0339 - accuracy: 0.9917 - f1_metric: 0.8301\n","2605/2605 [==============================] - 20s 7ms/step\n"]}]},{"cell_type":"markdown","source":["Oversampling using smote and train the model so that the ratio of all categories is more than 10%"],"metadata":{"id":"Sez2fS_OAkM6"},"id":"Sez2fS_OAkM6"},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n","from tensorflow.keras.callbacks import EarlyStopping\n","from imblearn.over_sampling import SMOTE\n","\n","# Custom F1 score metric function\n","def f1_metric(y_true, y_pred):\n","    true_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_true * y_pred, 0, 1)))\n","    possible_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_true, 0, 1)))\n","    predicted_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_pred, 0, 1)))\n","    precision = true_positives / (predicted_positives + tf.keras.backend.epsilon())\n","    recall = true_positives / (possible_positives + tf.keras.backend.epsilon())\n","    f1_val = 2 * (precision * recall) / (precision + recall + tf.keras.backend.epsilon())\n","    return f1_val\n","\n","# Load the data\n","train_data = pd.read_csv('train.csv')\n","test_data = pd.read_csv('test.csv')\n","\n","# Split the training data into training and validation sets\n","X_train, X_val, y_train, y_val = train_test_split(train_data['text'], train_data['label'], test_size=0.2, random_state=42)\n","\n","# Encode the labels\n","label_encoder = LabelEncoder()\n","y_train_encoded = label_encoder.fit_transform(y_train)\n","y_val_encoded = label_encoder.transform(y_val)\n","\n","# Tokenize the text data\n","max_features = 10000\n","max_len = 256\n","tokenizer = Tokenizer(num_words=max_features, oov_token='<OOV>')\n","tokenizer.fit_on_texts(X_train)\n","\n","X_train_sequences = tokenizer.texts_to_sequences(X_train)\n","X_val_sequences = tokenizer.texts_to_sequences(X_val)\n","X_train_padded = pad_sequences(X_train_sequences, maxlen=max_len, padding='post', truncating='post')\n","X_val_padded = pad_sequences(X_val_sequences, maxlen=max_len, padding='post', truncating='post')\n","\n","# Perform oversampling using SMOTE\n","smote = SMOTE(sampling_strategy='auto', random_state=42)\n","X_train_padded, y_train_encoded = smote.fit_resample(X_train_padded, y_train_encoded)\n","\n","# Define the neural network model\n","model = Sequential([\n","    Embedding(max_features, 128, input_length=max_len),\n","    LSTM(64, return_sequences=True),\n","    Dropout(0.2),\n","    LSTM(32),\n","    Dense(8, activation='softmax')\n","])\n","\n","# Compile and train the model\n","model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy', f1_metric])\n","early_stop = EarlyStopping(monitor='val_loss', patience=10)\n","history = model.fit(X_train_padded, y_train_encoded, epochs=30, validation_data=(X_val_padded, y_val_encoded), callbacks=[early_stop])\n","\n","# Refit the model with the combined data\n","X_train_val = pd.concat([X_train, X_val])\n","y_train_val_encoded = label_encoder.transform(pd.concat([y_train, y_val]))\n","\n","X_train_val_sequences = tokenizer.texts_to_sequences(X_train_val)\n","X_train_val_padded = pad_sequences(X_train_val_sequences, maxlen=max_len, padding='post', truncating='post')\n","\n","# Perform oversampling using SMOTE for the combined data\n","X_train_val_padded, y_train_val_encoded = smote.fit_resample(X_train_val_padded, y_train_val_encoded)\n","\n","# Refit the model with the combined data\n","model.fit(X_train_val_padded, y_train_val_encoded, epochs=5)\n","\n","# Prepare the test data\n","test_sequences = tokenizer.texts_to_sequences(test_data['text'])\n","test_padded = pad_sequences(test_sequences, maxlen=max_len, padding='post', truncating='post')\n","\n","# Make predictions on the test set\n","test_predictions = np.argmax(model.predict(test_padded), axis=-1)\n","\n","# Decode the predicted labels\n","test_labels_pred = label_encoder.inverse_transform(test_predictions)\n","\n","# Create a submission file\n","submission = pd.DataFrame({'id': test_data['id'], 'label': test_labels_pred})\n","submission.to_csv('submission_nn_model_oversample.csv', index=False)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aaSx-MYlKsEJ","executionInfo":{"status":"ok","timestamp":1680158871711,"user_tz":-540,"elapsed":1552297,"user":{"displayName":"지승영","userId":"07006377205744982370"}},"outputId":"919bed73-772a-4d6b-f490-384aea96d572"},"id":"aaSx-MYlKsEJ","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","2827/2827 [==============================] - 137s 47ms/step - loss: 1.5109 - accuracy: 0.3967 - f1_metric: 4.5778 - val_loss: 1.3087 - val_accuracy: 0.4185 - val_f1_metric: 1.6692\n","Epoch 2/30\n","2827/2827 [==============================] - 64s 23ms/step - loss: 1.2333 - accuracy: 0.5136 - f1_metric: 2.8648 - val_loss: 1.0927 - val_accuracy: 0.5257 - val_f1_metric: 1.7257\n","Epoch 3/30\n","2827/2827 [==============================] - 58s 21ms/step - loss: 0.9819 - accuracy: 0.6406 - f1_metric: 2.0490 - val_loss: 0.6767 - val_accuracy: 0.7609 - val_f1_metric: 1.0971\n","Epoch 4/30\n","2827/2827 [==============================] - 58s 20ms/step - loss: 0.7941 - accuracy: 0.7135 - f1_metric: 1.8340 - val_loss: 0.5144 - val_accuracy: 0.8145 - val_f1_metric: 0.9993\n","Epoch 5/30\n","2827/2827 [==============================] - 57s 20ms/step - loss: 0.6603 - accuracy: 0.7649 - f1_metric: 1.6624 - val_loss: 0.4606 - val_accuracy: 0.8391 - val_f1_metric: 1.0275\n","Epoch 6/30\n","2827/2827 [==============================] - 56s 20ms/step - loss: 0.5596 - accuracy: 0.8039 - f1_metric: 1.5098 - val_loss: 0.4293 - val_accuracy: 0.8521 - val_f1_metric: 0.9698\n","Epoch 7/30\n","2827/2827 [==============================] - 54s 19ms/step - loss: 0.4759 - accuracy: 0.8361 - f1_metric: 1.3924 - val_loss: 0.4369 - val_accuracy: 0.8557 - val_f1_metric: 0.9482\n","Epoch 8/30\n","2827/2827 [==============================] - 54s 19ms/step - loss: 0.4049 - accuracy: 0.8614 - f1_metric: 1.3046 - val_loss: 0.4440 - val_accuracy: 0.8568 - val_f1_metric: 0.9340\n","Epoch 9/30\n","2827/2827 [==============================] - 55s 19ms/step - loss: 0.3398 - accuracy: 0.8852 - f1_metric: 1.2374 - val_loss: 0.5015 - val_accuracy: 0.8519 - val_f1_metric: 0.9064\n","Epoch 10/30\n","2827/2827 [==============================] - 54s 19ms/step - loss: 0.2837 - accuracy: 0.9042 - f1_metric: 1.1813 - val_loss: 0.5594 - val_accuracy: 0.8515 - val_f1_metric: 0.8918\n","Epoch 11/30\n","2827/2827 [==============================] - 54s 19ms/step - loss: 0.2375 - accuracy: 0.9208 - f1_metric: 1.1339 - val_loss: 0.5826 - val_accuracy: 0.8495 - val_f1_metric: 0.8851\n","Epoch 12/30\n","2827/2827 [==============================] - 56s 20ms/step - loss: 0.2003 - accuracy: 0.9345 - f1_metric: 1.0947 - val_loss: 0.6369 - val_accuracy: 0.8505 - val_f1_metric: 0.8732\n","Epoch 13/30\n","2827/2827 [==============================] - 55s 19ms/step - loss: 0.1671 - accuracy: 0.9459 - f1_metric: 1.0645 - val_loss: 0.7072 - val_accuracy: 0.8424 - val_f1_metric: 0.8723\n","Epoch 14/30\n","2827/2827 [==============================] - 55s 19ms/step - loss: 0.1410 - accuracy: 0.9543 - f1_metric: 1.0407 - val_loss: 0.7083 - val_accuracy: 0.8451 - val_f1_metric: 0.8735\n","Epoch 15/30\n","2827/2827 [==============================] - 55s 20ms/step - loss: 0.1197 - accuracy: 0.9620 - f1_metric: 1.0211 - val_loss: 0.7224 - val_accuracy: 0.8403 - val_f1_metric: 0.8741\n","Epoch 16/30\n","2827/2827 [==============================] - 54s 19ms/step - loss: 0.1046 - accuracy: 0.9672 - f1_metric: 1.0083 - val_loss: 0.7525 - val_accuracy: 0.8427 - val_f1_metric: 0.8676\n","Epoch 1/5\n","3537/3537 [==============================] - 67s 19ms/step - loss: 0.5747 - accuracy: 0.7997 - f1_metric: 1.5349\n","Epoch 2/5\n","3537/3537 [==============================] - 67s 19ms/step - loss: 0.4460 - accuracy: 0.8431 - f1_metric: 1.4191\n","Epoch 3/5\n","3537/3537 [==============================] - 67s 19ms/step - loss: 0.3557 - accuracy: 0.8759 - f1_metric: 1.2998\n","Epoch 4/5\n","3537/3537 [==============================] - 77s 22ms/step - loss: 0.2750 - accuracy: 0.9050 - f1_metric: 1.2003\n","Epoch 5/5\n","3537/3537 [==============================] - 67s 19ms/step - loss: 0.2068 - accuracy: 0.9294 - f1_metric: 1.1220\n","2605/2605 [==============================] - 22s 8ms/step\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"eD-6egMcLh0E"},"id":"eD-6egMcLh0E","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.4"},"colab":{"provenance":[]},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"d2235bc38f514c1ab3e6704c2826c609":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_942497cdbc6844039c99e844cbcb0427","IPY_MODEL_0ddaf4e1dca24553926e6ad03b06205e","IPY_MODEL_ab72dbfe3d36471383022d1936544705"],"layout":"IPY_MODEL_4ea1ac624a0e4c7586480652dfe82d4c"}},"942497cdbc6844039c99e844cbcb0427":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6a772397970a4c669113e43b4669d73d","placeholder":"​","style":"IPY_MODEL_cd7abff733aa4cdfa1d83443fd59db0f","value":"Downloading (…)okenizer_config.json: 100%"}},"0ddaf4e1dca24553926e6ad03b06205e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0d4b26fef0a441408ba66708047e2a26","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5005d5d2a6f348398f37be5424aac3f2","value":28}},"ab72dbfe3d36471383022d1936544705":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3f985e100a7a493b9af0d96093776520","placeholder":"​","style":"IPY_MODEL_986ea41221de4d269ffbd030fbce82f3","value":" 28.0/28.0 [00:00&lt;00:00, 234B/s]"}},"4ea1ac624a0e4c7586480652dfe82d4c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a772397970a4c669113e43b4669d73d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd7abff733aa4cdfa1d83443fd59db0f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0d4b26fef0a441408ba66708047e2a26":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5005d5d2a6f348398f37be5424aac3f2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3f985e100a7a493b9af0d96093776520":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"986ea41221de4d269ffbd030fbce82f3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"229a9b4f7f1b481f99e50050172d6949":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_15e0011cc9f540f2ba0217f50602291d","IPY_MODEL_750edc84afa74377bfc8ec3b59a42172","IPY_MODEL_a9fe05ffd7f242079cc398f78b47a7b6"],"layout":"IPY_MODEL_6b450b0338ba427181f64299f499e942"}},"15e0011cc9f540f2ba0217f50602291d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9f1cc170c7b84acea16123af070dae70","placeholder":"​","style":"IPY_MODEL_7c6f7269cdd3484799db806a536a767c","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"750edc84afa74377bfc8ec3b59a42172":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_09073d7273824416a3b72837c418365e","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cfc51cc99e6144e59546669724591f35","value":231508}},"a9fe05ffd7f242079cc398f78b47a7b6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f859a752856d45d48bc418fcc33cc658","placeholder":"​","style":"IPY_MODEL_c45b2f865c144155a12bb1f0fa873414","value":" 232k/232k [00:00&lt;00:00, 1.07MB/s]"}},"6b450b0338ba427181f64299f499e942":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f1cc170c7b84acea16123af070dae70":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c6f7269cdd3484799db806a536a767c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"09073d7273824416a3b72837c418365e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cfc51cc99e6144e59546669724591f35":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f859a752856d45d48bc418fcc33cc658":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c45b2f865c144155a12bb1f0fa873414":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a7ecf2d36f954f778d76e84bd3492ef6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cbf13baa3fad463e88e7fe637bc58ab9","IPY_MODEL_ff509959530f4d5dbeaeef2c4be82c1d","IPY_MODEL_0a079a37cb6241b798f211460e1e4a08"],"layout":"IPY_MODEL_a810086781a842ae9050b535c4c6f565"}},"cbf13baa3fad463e88e7fe637bc58ab9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3c10173d3b5c493d9833745ff25e0b48","placeholder":"​","style":"IPY_MODEL_ed13ab613f474b6da995d48629667b7e","value":"Downloading (…)/main/tokenizer.json: 100%"}},"ff509959530f4d5dbeaeef2c4be82c1d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5f168c47a21343a69b3f59cb0410d627","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2ba7be9513da4891bf4e4d8894ed3b9d","value":466062}},"0a079a37cb6241b798f211460e1e4a08":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ea918ef096304eae9f45244a63e433a2","placeholder":"​","style":"IPY_MODEL_a49ea5d722c64be68f1a8b5ac1368a9e","value":" 466k/466k [00:00&lt;00:00, 2.30MB/s]"}},"a810086781a842ae9050b535c4c6f565":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c10173d3b5c493d9833745ff25e0b48":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ed13ab613f474b6da995d48629667b7e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5f168c47a21343a69b3f59cb0410d627":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ba7be9513da4891bf4e4d8894ed3b9d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ea918ef096304eae9f45244a63e433a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a49ea5d722c64be68f1a8b5ac1368a9e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d54300b013b94d059a13780f1e0527e2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_75efa1e9c70448ef94b08fde1011a921","IPY_MODEL_c5d23b2f7b204ee9a00524e5c2d7b6f2","IPY_MODEL_1b221b7cf81b4fdeaa0c87336a66a1ae"],"layout":"IPY_MODEL_1f28e9cf30174dc691c41aa770045be7"}},"75efa1e9c70448ef94b08fde1011a921":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b1dd1e720c5142dabfbc62d5768945f7","placeholder":"​","style":"IPY_MODEL_f0897ec014524f3fa09f56c35e765329","value":"Downloading (…)lve/main/config.json: 100%"}},"c5d23b2f7b204ee9a00524e5c2d7b6f2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b4def8a04673453ca89e11e51b3ea2dd","max":483,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f7e3a3a2a1184df2bf3f85cb6dc6169d","value":483}},"1b221b7cf81b4fdeaa0c87336a66a1ae":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_98a0706280994a649129db105365fe81","placeholder":"​","style":"IPY_MODEL_924cc3e09e2a4697aa7fc60737416d9d","value":" 483/483 [00:00&lt;00:00, 6.24kB/s]"}},"1f28e9cf30174dc691c41aa770045be7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b1dd1e720c5142dabfbc62d5768945f7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f0897ec014524f3fa09f56c35e765329":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b4def8a04673453ca89e11e51b3ea2dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f7e3a3a2a1184df2bf3f85cb6dc6169d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"98a0706280994a649129db105365fe81":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"924cc3e09e2a4697aa7fc60737416d9d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}
=======
{"cells":[{"cell_type":"code","execution_count":3,"id":"c0bf904f","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c0bf904f","executionInfo":{"status":"ok","timestamp":1680150965238,"user_tz":-540,"elapsed":11972,"user":{"displayName":"지승영","userId":"07006377205744982370"}},"outputId":"0f0a49a9-3f28-471c-ece9-2cb6417c99f9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.27.4-py3-none-any.whl (6.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.7)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n","Collecting huggingface-hub<1.0,>=0.11.0\n","  Downloading huggingface_hub-0.13.3-py3-none-any.whl (199 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 KB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.13.3 tokenizers-0.13.2 transformers-4.27.4\n"]}],"source":["pip install transformers "]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gn4fxE6Ny6IX","executionInfo":{"status":"ok","timestamp":1680150941313,"user_tz":-540,"elapsed":32983,"user":{"displayName":"지승영","userId":"07006377205744982370"}},"outputId":"67056a80-0eeb-46df-c9ed-53179b5d698d"},"id":"Gn4fxE6Ny6IX","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import os\n","os.chdir('/content/drive/MyDrive/github/Dacon/chatgpt경진대회')\n","os.getcwd()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"R4fnj5Ycza1j","executionInfo":{"status":"ok","timestamp":1680154505094,"user_tz":-540,"elapsed":805,"user":{"displayName":"지승영","userId":"07006377205744982370"}},"outputId":"81fa9892-319c-43ea-abfa-6eb115787ef2"},"id":"R4fnj5Ycza1j","execution_count":1,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/github/Dacon/chatgpt경진대회'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":1}]},{"cell_type":"markdown","source":["+ 프롬프트1\n","good!\n","I want to change model.\n","I want to use neural network model to predict news category by article.\n","Give me the sota model code for news category classification.\n","\n","use train.csv for model training and validation.\n","And make submission file 'submission_nnmodel.csv' from test.csv\n","\n","train epoch is 30 and metric is f1 score.\n","if there is no improvment until 10 epochs, then stop training and predict test label.\n","\n","+ 프롬프트2\n","good.\n","But you have to make submission_nnmodel.csv file from test.csv and your model.\n","And before make submission_nnmodel.csv file\n","train validation set to model\n","\n","\n","+ 프롬프트3\n","잘했어. 1개의 코드로 합쳐서 다시 적어줘\n","\n","+ 프롬프트4\n","답변이 짤리는데, 두 개로 나눠서 작성해줘\n","\n","+ 프롬프트5\n","part2가 잘렸어. \n","마저 작성해줘\n","\n"],"metadata":{"id":"wQAmqgJD204e"},"id":"wQAmqgJD204e"},{"cell_type":"code","source":["import pandas as pd\n","import torch\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import f1_score\n","from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, Trainer, TrainingArguments\n","\n","# Load the training data\n","train_data = pd.read_csv('train.csv')\n","\n","# Load the testing data\n","test_data = pd.read_csv('test.csv')\n","\n","# Split the training data into training and validation sets\n","X_train, X_val, y_train, y_val = train_test_split(train_data['text'], train_data['label'], test_size=0.2, random_state=42)\n","\n","# Encode the labels\n","label_encoder = LabelEncoder()\n","y_train_encoded = label_encoder.fit_transform(y_train)\n","y_val_encoded = label_encoder.transform(y_val)\n","\n","# Tokenize the text data\n","tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n","\n","train_encodings = tokenizer(X_train.tolist(), truncation=True, padding=True, max_length=512)\n","val_encodings = tokenizer(X_val.tolist(), truncation=True, padding=True, max_length=512)\n","\n","# Create a custom dataset class\n","class NewsDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        item['labels'] = torch.tensor(self.labels[idx])\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","# Create dataset objects for train and validation data\n","train_dataset = NewsDataset(train_encodings, y_train_encoded)\n","val_dataset = NewsDataset(val_encodings, y_val_encoded)\n","\n","# Compute the weighted F1 score metric\n","def compute_metrics(eval_pred):\n","    logits, labels = eval_pred\n","    predictions = np.argmax(logits, axis=-1)\n","    f1 = f1_score(labels, predictions, average='weighted')\n","    return {'f1': f1}\n","\n","# Training arguments\n","training_args = TrainingArguments(\n","    output_dir='./results',\n","    num_train_epochs=30,\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    logging_dir='./logs',\n","    logging_steps=50,\n","    save_steps=50,\n","    save_total_limit=1,\n","    load_best_model_at_end=True,\n","    metric_for_best_model='f1',\n","    evaluation_strategy='epoch',\n","    report_to='none',\n","    gradient_accumulation_steps=1,\n","    fp16=True,\n","    warmup_steps=50,\n","    weight_decay=0.01,\n","    adam_beta1=0.9,\n","    adam_beta2=0.999,\n","    adam_epsilon=1e-8,\n","    learning_rate=5e-5,\n","    early_stopping_patience=10\n",")\n","\n","# Initialize the model\n","num_labels = len(label_encoder.classes_)\n","model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=num_labels)\n","\n","# Create the Trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    compute_metrics=compute_metrics\n",")\n","\n","# Train the model\n","trainer.train()\n","\n","# Combine the training and validation sets for refitting\n","X_train_val = pd.concat([X_train, X_val])\n","y_train_val_encoded = label_encoder.transform(pd.concat([y_train, y_val]))\n","\n","\n","# Tokenize and create a dataset object for the combined data\n","train_val_encodings = tokenizer(X_train_val.tolist(), truncation=True, padding=True, max_length=512)\n","train_val_dataset = NewsDataset(train_val_encodings, y_train_val_encoded)\n","\n","# Update the training arguments for refitting\n","training_args.num_train_epochs = 5\n","trainer.args = training_args\n","trainer.train_dataset = train_val_dataset\n","\n","# Refit the model with the combined data\n","trainer.train()\n","\n","# Tokenize the test data\n","test_encodings = tokenizer(test_data['text'].tolist(), truncation=True, padding=True, max_length=512)\n","\n","# Create a dataset object for the test data without labels\n","test_dataset = NewsDataset(test_encodings, [0] * len(test_data))\n","\n","# Make predictions on the test set\n","test_predictions = trainer.predict(test_dataset).predictions\n","test_data['label'] = label_encoder.inverse_transform(np.argmax(test_predictions, axis=-1))\n","\n","# Save the submission file\n","submission = test_data[['id', 'label']]\n","submission.to_csv('submission_nnmodel.csv', index=False)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":379,"referenced_widgets":["d2235bc38f514c1ab3e6704c2826c609","942497cdbc6844039c99e844cbcb0427","0ddaf4e1dca24553926e6ad03b06205e","ab72dbfe3d36471383022d1936544705","4ea1ac624a0e4c7586480652dfe82d4c","6a772397970a4c669113e43b4669d73d","cd7abff733aa4cdfa1d83443fd59db0f","0d4b26fef0a441408ba66708047e2a26","5005d5d2a6f348398f37be5424aac3f2","3f985e100a7a493b9af0d96093776520","986ea41221de4d269ffbd030fbce82f3","229a9b4f7f1b481f99e50050172d6949","15e0011cc9f540f2ba0217f50602291d","750edc84afa74377bfc8ec3b59a42172","a9fe05ffd7f242079cc398f78b47a7b6","6b450b0338ba427181f64299f499e942","9f1cc170c7b84acea16123af070dae70","7c6f7269cdd3484799db806a536a767c","09073d7273824416a3b72837c418365e","cfc51cc99e6144e59546669724591f35","f859a752856d45d48bc418fcc33cc658","c45b2f865c144155a12bb1f0fa873414","a7ecf2d36f954f778d76e84bd3492ef6","cbf13baa3fad463e88e7fe637bc58ab9","ff509959530f4d5dbeaeef2c4be82c1d","0a079a37cb6241b798f211460e1e4a08","a810086781a842ae9050b535c4c6f565","3c10173d3b5c493d9833745ff25e0b48","ed13ab613f474b6da995d48629667b7e","5f168c47a21343a69b3f59cb0410d627","2ba7be9513da4891bf4e4d8894ed3b9d","ea918ef096304eae9f45244a63e433a2","a49ea5d722c64be68f1a8b5ac1368a9e","d54300b013b94d059a13780f1e0527e2","75efa1e9c70448ef94b08fde1011a921","c5d23b2f7b204ee9a00524e5c2d7b6f2","1b221b7cf81b4fdeaa0c87336a66a1ae","1f28e9cf30174dc691c41aa770045be7","b1dd1e720c5142dabfbc62d5768945f7","f0897ec014524f3fa09f56c35e765329","b4def8a04673453ca89e11e51b3ea2dd","f7e3a3a2a1184df2bf3f85cb6dc6169d","98a0706280994a649129db105365fe81","924cc3e09e2a4697aa7fc60737416d9d"]},"id":"ivsEgxDsy6m7","executionInfo":{"status":"error","timestamp":1680151936700,"user_tz":-540,"elapsed":148845,"user":{"displayName":"지승영","userId":"07006377205744982370"}},"outputId":"0e26e973-38ba-43d8-e250-ad631b852c2c"},"id":"ivsEgxDsy6m7","execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2235bc38f514c1ab3e6704c2826c609"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"229a9b4f7f1b481f99e50050172d6949"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a7ecf2d36f954f778d76e84bd3492ef6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d54300b013b94d059a13780f1e0527e2"}},"metadata":{}},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-f66b10d88305>\u001b[0m in \u001b[0;36m<cell line: 55>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;31m# Training arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m training_args = TrainingArguments(\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./results'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mnum_train_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'early_stopping_patience'"]}]},{"cell_type":"markdown","source":["\n","+ 프롬프트 6\n","I got an error. plz fix it and give me code again\n","\n","     54 # Training arguments\n","---> 55 training_args = TrainingArguments(\n","     56     output_dir='./results',\n","     57     num_train_epochs=30,\n","\n","TypeError: __init__() got an unexpected keyword argument 'early_stopping_patience'\n","\n","+ 프롬프트 7\n","\n","이어서 마저 작성해줘"],"metadata":{"id":"a3EC4yK13r7C"},"id":"a3EC4yK13r7C"},{"cell_type":"code","source":["import pandas as pd\n","import torch\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import f1_score\n","from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, Trainer, TrainingArguments\n","from transformers.trainer_callback import EarlyStoppingCallback\n","\n","# Load the training data\n","train_data = pd.read_csv('train.csv')\n","\n","# Load the testing data\n","test_data = pd.read_csv('test.csv')\n","\n","# Split the training data into training and validation sets\n","X_train, X_val, y_train, y_val = train_test_split(train_data['text'], train_data['label'], test_size=0.2, random_state=42)\n","\n","# Encode the labels\n","label_encoder = LabelEncoder()\n","y_train_encoded = label_encoder.fit_transform(y_train)\n","y_val_encoded = label_encoder.transform(y_val)\n","\n","# Tokenize the text data\n","tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n","\n","train_encodings = tokenizer(X_train.tolist(), truncation=True, padding=True, max_length=512)\n","val_encodings = tokenizer(X_val.tolist(), truncation=True, padding=True, max_length=512)\n","\n","# Create a custom dataset class\n","class NewsDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        item['labels'] = torch.tensor(self.labels[idx])\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","# Create dataset objects for train and validation data\n","train_dataset = NewsDataset(train_encodings, y_train_encoded)\n","val_dataset = NewsDataset(val_encodings, y_val_encoded)\n","\n","# Compute the weighted F1 score metric\n","def compute_metrics(eval_pred):\n","    logits, labels = eval_pred\n","    predictions = np.argmax(logits, axis=-1)\n","    f1 = f1_score(labels, predictions, average='weighted')\n","    return {'f1': f1}\n","\n","# Training arguments\n","training_args = TrainingArguments(\n","    output_dir='./results',\n","    num_train_epochs=30,\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    logging_dir='./logs',\n","    logging_steps=50,\n","    save_steps=50,\n","    save_total_limit=1,\n","    load_best_model_at_end=True,\n","    metric_for_best_model='f1',\n","    evaluation_strategy='epoch',\n","    report_to='none',\n","    gradient_accumulation_steps=1,\n","    fp16=True,\n","    warmup_steps=50,\n","    weight_decay=0.01,\n","    adam_beta1=0.9,\n","    adam_beta2=0.999,\n","    adam_epsilon=1e-8,\n","    learning_rate=5e-5,\n",")\n","\n","# Initialize the model\n","num_labels = len(label_encoder.classes_)\n","model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=num_labels)\n","\n","# Create the Trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    compute_metrics=compute_metrics,\n","    callbacks=[EarlyStoppingCallback(patience=10)]\n",")\n","\n","# Train the model\n","trainer.train()\n","\n","# Combine the training and validation sets for refitting\n","X_train_val = pd.concat([X_train, X_val])\n","y_train_val_encoded = label_encoder.transform(pd.concat([y_train, y_val]))\n","\n","# Tokenize and create a dataset object for the combined data\n","train_val_encodings = tokenizer(X_train_val.tolist(), truncation=True, padding=True, max_length=512)\n","train_val_dataset = NewsDataset(train_val_encodings, y_train_val_encoded)\n","\n","# Update the training arguments for refitting\n","training_args.num_train_epochs = 5\n","trainer.args = training_args\n","trainer.train_dataset = train_val_dataset\n","\n","# Refit the model with the combined data\n","trainer.train()\n","\n","# Tokenize the test data\n","test_encodings = tokenizer(test_data['text'].tolist(), truncation=True, padding=True, max_length=512)\n","\n","# Create a dataset object for the test data without labels\n","test_dataset = NewsDataset(test_encodings, [0] * len(test_data))\n","\n","# Make predictions on the test set\n","test_predictions = trainer.predict(test_dataset).predictions\n","test_data['label'] = label_encoder.inverse_transform(np.argmax(test_predictions, axis=-1))\n","\n","# Save the submission file\n","submission = test_data[['id', 'label']]\n","submission.to_csv('submission_nnmodel.csv', index=False)\n"],"metadata":{"id":"aT8LSLabzOkJ"},"id":"aT8LSLabzOkJ","execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Jey_UQzb3zE4"},"id":"Jey_UQzb3zE4","execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import torch\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import f1_score\n","from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, Trainer, TrainingArguments\n","from transformers.trainer_callback import EarlyStoppingCallback\n","\n","# Load the training data\n","train_data = pd.read_csv('train.csv')\n","\n","# Load the testing data\n","test_data = pd.read_csv('test.csv')\n","\n","# Split the training data into training and validation sets\n","X_train, X_val, y_train, y_val = train_test_split(train_data['text'], train_data['label'], test_size=0.2, random_state=42)\n","\n","# Encode the labels\n","label_encoder = LabelEncoder()\n","y_train_encoded = label_encoder.fit_transform(y_train)\n","y_val_encoded = label_encoder.transform(y_val)\n","\n","# Tokenize the text data\n","tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n","\n","train_encodings = tokenizer(X_train.tolist(), truncation=True, padding=True, max_length=256)\n","val_encodings = tokenizer(X_val.tolist(), truncation=True, padding=True, max_length=256)\n","\n","# Create a custom dataset class\n","class NewsDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        item['labels'] = torch.tensor(self.labels[idx])\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","# Create dataset objects for train and validation data\n","train_dataset = NewsDataset(train_encodings, y_train_encoded)\n","val_dataset = NewsDataset(val_encodings, y_val_encoded)\n","\n","# Compute the weighted F1 score metric\n","def compute_metrics(eval_pred):\n","    logits, labels = eval_pred\n","    predictions = np.argmax(logits, axis=-1)\n","    f1 = f1_score(labels, predictions, average='weighted')\n","    return {'f1': f1}\n","\n","# Training arguments\n","training_args = TrainingArguments(\n","    output_dir='./results',\n","    num_train_epochs=30,\n","    per_device_train_batch_size=4,\n","    per_device_eval_batch_size=4,\n","    logging_dir='./logs',\n","    logging_steps=50,\n","    save_steps=50,\n","    save_total_limit=1,\n","    load_best_model_at_end=True,\n","    metric_for_best_model='f1',\n","    evaluation_strategy='epoch',\n","    report_to='none',\n","    gradient_accumulation_steps=1,\n","    fp16=True,\n","    warmup_steps=50,\n","    weight_decay=0.01,\n","    adam_beta1=0.9,\n","    adam_beta2=0.999,\n","    adam_epsilon=1e-8,\n","    learning_rate=5e-5,\n",")\n","\n","# Initialize the model\n","num_labels = len(label_encoder.classes_)\n","model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=num_labels)\n","\n","# Create the Trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    compute_metrics=compute_metrics,\n","    callbacks=[EarlyStoppingCallback(patience=10)]\n",")\n","\n","# Train the model\n","trainer.train()\n","\n","# Combine the training and validation sets for refitting\n","# Combine the training and validation sets for refitting\n","X_train_val = pd.concat([X_train, X_val])\n","y_train_val_encoded = label_encoder.transform(pd.concat([y_train, y_val]))\n","\n","# Tokenize and create a dataset object for the combined data\n","train_val_encodings = tokenizer(X_train_val.tolist(), truncation=True, padding=True, max_length=256)\n","train_val_dataset = NewsDataset(train_val_encodings, y_train_val_encoded)\n","\n","# Update the training arguments for refitting\n","training_args.num_train_epochs = 5\n","trainer.args = training_args\n","trainer.train_dataset = train_val_dataset\n","\n","# Refit the model with the combined data\n","trainer.train()\n","\n","# Tokenize the test data\n","test_encodings = tokenizer(test_data['text'].tolist(), truncation=True, padding=True, max_length=256)\n","\n","# Create a dataset object for the test data without labels\n","test_dataset = NewsDataset(test_encodings, [0] * len(test_data))\n","\n","# Make predictions on the test set\n","test_predictions = trainer.predict(test_dataset).predictions\n","test_data['label'] = label_encoder.inverse_transform(np.argmax(test_predictions, axis=-1))\n","\n","# Save the submission file\n","submission = test_data[['id', 'label']]\n","submission.to_csv('submission_nnmodel.csv', index=False)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":461},"id":"2oKKBjXF44Ma","executionInfo":{"status":"error","timestamp":1680152588491,"user_tz":-540,"elapsed":91476,"user":{"displayName":"지승영","userId":"07006377205744982370"}},"outputId":"b530c729-fb69-486c-f2dc-5367a22f3794"},"id":"2oKKBjXF44Ma","execution_count":4,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-153d14f3d04c>\u001b[0m in \u001b[0;36m<cell line: 56>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;31m# Training arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m training_args = TrainingArguments(\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./results'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mnum_train_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/training_args.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, output_dir, overwrite_output_dir, do_train, do_eval, do_predict, evaluation_strategy, prediction_loss_only, per_device_train_batch_size, per_device_eval_batch_size, per_gpu_train_batch_size, per_gpu_eval_batch_size, gradient_accumulation_steps, eval_accumulation_steps, eval_delay, learning_rate, weight_decay, adam_beta1, adam_beta2, adam_epsilon, max_grad_norm, num_train_epochs, max_steps, lr_scheduler_type, warmup_ratio, warmup_steps, log_level, log_level_replica, log_on_each_node, logging_dir, logging_strategy, logging_first_step, logging_steps, logging_nan_inf_filter, save_strategy, save_steps, save_total_limit, save_on_each_node, no_cuda, use_mps_device, seed, data_seed, jit_mode_eval, use_ipex, bf16, fp16, fp16_opt_level, half_precision_backend, bf16_full_eval, fp16_full_eval, tf32, local_rank, xpu_backend, tpu_num_cores, tpu_metrics_debug, debug, dataloader_drop_last, eval_steps, dataloader_num_workers, past_index, run_name, disable_tqdm, remove_unused_columns, label_names, load_best_model_at_end, metric_for_best_model, greater_is_better, ignore_data_skip, sharded_ddp, fsdp, fsdp_min_num_params, fsdp_config, fsdp_transformer_layer_cls_to_wrap, deepspeed, label_smoothing_factor, optim, optim_args, adafactor, group_by_length, length_column_name, report_to, ddp_find_unused_parameters, ddp_bucket_cap_mb, dataloader_pin_memory, skip_memory_metrics, use_legacy_pr...\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/training_args.py\u001b[0m in \u001b[0;36m__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1157\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_best_model_at_end\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_strategy\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_strategy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1159\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m   1160\u001b[0m                     \u001b[0;34m\"--load_best_model_at_end requires the save and eval strategy to match, but found\\n- Evaluation \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m                     \u001b[0;34mf\"strategy: {self.evaluation_strategy}\\n- Save strategy: {self.save_strategy}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: --load_best_model_at_end requires the save and eval strategy to match, but found\n- Evaluation strategy: epoch\n- Save strategy: steps"]}]},{"cell_type":"code","source":["import pandas as pd\n","import torch\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import f1_score\n","from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, Trainer, TrainingArguments\n","from transformers.trainer_callback import EarlyStoppingCallback\n","\n","# Load the training data\n","train_data = pd.read_csv('train.csv')\n","\n","# Load the testing data\n","test_data = pd.read_csv('test.csv')\n","\n","# Split the training data into training and validation sets\n","X_train, X_val, y_train, y_val = train_test_split(train_data['text'], train_data['label'], test_size=0.2, random_state=42)\n","\n","# Encode the labels\n","label_encoder = LabelEncoder()\n","y_train_encoded = label_encoder.fit_transform(y_train)\n","y_val_encoded = label_encoder.transform(y_val)\n","\n","# Tokenize the text data\n","tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n","\n","train_encodings = tokenizer(X_train.tolist(), truncation=True, padding=True, max_length=256)\n","val_encodings = tokenizer(X_val.tolist(), truncation=True, padding=True, max_length=256)\n","\n","# Create a custom dataset class\n","class NewsDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        item['labels'] = torch.tensor(self.labels[idx])\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","# Create dataset objects for train and validation data\n","train_dataset = NewsDataset(train_encodings, y_train_encoded)\n","val_dataset = NewsDataset(val_encodings, y_val_encoded)\n","\n","# Compute the weighted F1 score metric\n","def compute_metrics(eval_pred):\n","    logits, labels = eval_pred\n","    predictions = np.argmax(logits, axis=-1)\n","    f1 = f1_score(labels, predictions, average='weighted')\n","    return {'f1': f1}\n","\n","# Training arguments\n","training_args = TrainingArguments(\n","    output_dir='./results',\n","    num_train_epochs=30,\n","    per_device_train_batch_size=4,\n","    per_device_eval_batch_size=4,\n","    logging_dir='./logs',\n","    logging_steps=50,\n","    save_steps=50,\n","    save_total_limit=1,\n","    load_best_model_at_end=True,\n","    metric_for_best_model='f1',\n","    evaluation_strategy='epoch',\n","    report_to='none',\n","    gradient_accumulation_steps=1,\n","    fp16=True,\n","    warmup_steps=50,\n","    weight_decay=0.01,\n","    adam_beta1=0.9,\n","    adam_beta2=0.999,\n","    adam_epsilon=1e-8,\n","    learning_rate=5e-5,\n",")\n","\n","\n","# Initialize the model\n","num_labels = len(label_encoder.classes_)\n","model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=num_labels)\n","\n","# Create the Trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    compute_metrics=compute_metrics,\n","    callbacks=[EarlyStoppingCallback(patience=10)]\n",")\n","\n","# Train the model\n","trainer.train()\n","\n","# Combine the training and validation sets for refitting\n","X_train_val = pd.concat([X_train, X_val])\n","y_train_val_encoded = label_encoder.transform(pd.concat([y_train, y_val]))\n","\n","# Tokenize and create a dataset object for the combined data\n","train_val_encodings = tokenizer(X_train_val.tolist(), truncation=True, padding=True, max_length=256)\n","train_val_dataset = NewsDataset(train_val_encodings, y_train_val_encoded)\n","\n","# Update the training arguments for refitting\n","training_args.num_train_epochs = 5\n","training_args.save_strategy = 'epoch'  # Set save_strategy to match evaluation_strategy\n","trainer.args = training_args\n","trainer.train_dataset = train_val_dataset\n","\n","# Refit the model with the combined data\n","trainer.train()\n","\n","# Tokenize the test data\n","test_encodings = tokenizer(test_data['text'].tolist(), truncation=True, padding=True, max_length=256)\n","\n","# Create a dataset object for the test data without labels\n","test_dataset = NewsDataset(test_encodings, [0] * len(test_data))\n","\n","# Make predictions on the test set\n","test_predictions = trainer.predict(test_dataset).predictions\n","test_data['label'] = label_encoder.inverse_transform(np.argmax(test_predictions, axis=-1))\n","\n","# Save the submission file\n","submission = test_data[['id', 'label']]\n","submission.to_csv('submission_nnmodel.csv', index=False)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":461},"id":"XbmjThbA47YW","executionInfo":{"status":"error","timestamp":1680154277470,"user_tz":-540,"elapsed":97409,"user":{"displayName":"지승영","userId":"07006377205744982370"}},"outputId":"1b767271-9c36-4c26-b13d-bad5d1b65c68"},"id":"XbmjThbA47YW","execution_count":3,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-2f47557e4d3d>\u001b[0m in \u001b[0;36m<cell line: 56>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;31m# Training arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m training_args = TrainingArguments(\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./results'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mnum_train_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/training_args.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, output_dir, overwrite_output_dir, do_train, do_eval, do_predict, evaluation_strategy, prediction_loss_only, per_device_train_batch_size, per_device_eval_batch_size, per_gpu_train_batch_size, per_gpu_eval_batch_size, gradient_accumulation_steps, eval_accumulation_steps, eval_delay, learning_rate, weight_decay, adam_beta1, adam_beta2, adam_epsilon, max_grad_norm, num_train_epochs, max_steps, lr_scheduler_type, warmup_ratio, warmup_steps, log_level, log_level_replica, log_on_each_node, logging_dir, logging_strategy, logging_first_step, logging_steps, logging_nan_inf_filter, save_strategy, save_steps, save_total_limit, save_on_each_node, no_cuda, use_mps_device, seed, data_seed, jit_mode_eval, use_ipex, bf16, fp16, fp16_opt_level, half_precision_backend, bf16_full_eval, fp16_full_eval, tf32, local_rank, xpu_backend, tpu_num_cores, tpu_metrics_debug, debug, dataloader_drop_last, eval_steps, dataloader_num_workers, past_index, run_name, disable_tqdm, remove_unused_columns, label_names, load_best_model_at_end, metric_for_best_model, greater_is_better, ignore_data_skip, sharded_ddp, fsdp, fsdp_min_num_params, fsdp_config, fsdp_transformer_layer_cls_to_wrap, deepspeed, label_smoothing_factor, optim, optim_args, adafactor, group_by_length, length_column_name, report_to, ddp_find_unused_parameters, ddp_bucket_cap_mb, dataloader_pin_memory, skip_memory_metrics, use_legacy_pr...\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/training_args.py\u001b[0m in \u001b[0;36m__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1157\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_best_model_at_end\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_strategy\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_strategy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1159\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m   1160\u001b[0m                     \u001b[0;34m\"--load_best_model_at_end requires the save and eval strategy to match, but found\\n- Evaluation \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m                     \u001b[0;34mf\"strategy: {self.evaluation_strategy}\\n- Save strategy: {self.save_strategy}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: --load_best_model_at_end requires the save and eval strategy to match, but found\n- Evaluation strategy: epoch\n- Save strategy: steps"]}]},{"cell_type":"markdown","source":["I want to use other Neural Network model.\n","I want much shorter code.\n","please give me a python code."],"metadata":{"id":"0X_3OxzjAk-I"},"id":"0X_3OxzjAk-I"},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","# Load the data\n","train_data = pd.read_csv('train.csv')\n","test_data = pd.read_csv('test.csv')\n","\n","# Split the training data into training and validation sets\n","X_train, X_val, y_train, y_val = train_test_split(train_data['text'], train_data['label'], test_size=0.2, random_state=42)\n","\n","# Encode the labels\n","label_encoder = LabelEncoder()\n","y_train_encoded = label_encoder.fit_transform(y_train)\n","y_val_encoded = label_encoder.transform(y_val)\n","\n","# Tokenize the text data\n","max_features = 10000\n","max_len = 256\n","tokenizer = Tokenizer(num_words=max_features, oov_token='<OOV>')\n","tokenizer.fit_on_texts(X_train)\n","\n","X_train_sequences = tokenizer.texts_to_sequences(X_train)\n","X_val_sequences = tokenizer.texts_to_sequences(X_val)\n","X_train_padded = pad_sequences(X_train_sequences, maxlen=max_len, padding='post', truncating='post')\n","X_val_padded = pad_sequences(X_val_sequences, maxlen=max_len, padding='post', truncating='post')\n","\n","# Define the neural network model\n","model = Sequential([\n","    Embedding(max_features, 128, input_length=max_len),\n","    LSTM(64, return_sequences=True),\n","    Dropout(0.2),\n","    LSTM(32),\n","    Dense(8, activation='softmax')\n","])\n","\n","# Compile and train the model\n","model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","early_stop = EarlyStopping(monitor='val_loss', patience=10)\n","model.fit(X_train_padded, y_train_encoded, epochs=30, validation_data=(X_val_padded, y_val_encoded), callbacks=[early_stop])\n","\n","# Refit the model with the combined data\n","X_train_val = pd.concat([X_train, X_val])\n","y_train_val_encoded = label_encoder.transform(pd.concat([y_train, y_val]))\n","\n","X_train_val_sequences = tokenizer.texts_to_sequences(X_train_val)\n","X_train_val_padded = pad_sequences(X_train_val_sequences, maxlen=max_len, padding='post', truncating='post')\n","model.fit(X_train_val_padded, y_train_val_encoded, epochs=5)\n","\n","# Prepare the test data\n","test_sequences = tokenizer.texts_to_sequences(test_data['text'])\n","test_padded = pad_sequences(test_sequences, maxlen=max_len, padding='post', truncating='post')\n","\n","# Make predictions on the test set\n","test_predictions = np.argmax(model.predict(test_padded), axis=-1)\n","test_data['label'] = label_encoder.inverse_transform(test_predictions)\n","\n","# Save the submission file\n","submission = test_data[['id', 'label']]\n","submission.to_csv('submission_nnmodel.csv', index=False)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"86HN91ze-6tH","executionInfo":{"status":"ok","timestamp":1680155385417,"user_tz":-540,"elapsed":873754,"user":{"displayName":"지승영","userId":"07006377205744982370"}},"outputId":"80b35941-4012-47bc-e99c-e5e4f188fa53"},"id":"86HN91ze-6tH","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","1185/1185 [==============================] - 126s 98ms/step - loss: 1.0889 - accuracy: 0.5649 - val_loss: 0.7338 - val_accuracy: 0.7637\n","Epoch 2/30\n","1185/1185 [==============================] - 44s 37ms/step - loss: 1.0432 - accuracy: 0.6109 - val_loss: 1.1151 - val_accuracy: 0.5697\n","Epoch 3/30\n","1185/1185 [==============================] - 33s 28ms/step - loss: 0.8459 - accuracy: 0.6988 - val_loss: 0.6683 - val_accuracy: 0.7907\n","Epoch 4/30\n","1185/1185 [==============================] - 29s 25ms/step - loss: 0.5323 - accuracy: 0.8327 - val_loss: 0.5386 - val_accuracy: 0.8215\n","Epoch 5/30\n","1185/1185 [==============================] - 28s 24ms/step - loss: 0.4181 - accuracy: 0.8683 - val_loss: 0.4732 - val_accuracy: 0.8437\n","Epoch 6/30\n","1185/1185 [==============================] - 27s 22ms/step - loss: 0.3515 - accuracy: 0.8891 - val_loss: 0.4902 - val_accuracy: 0.8374\n","Epoch 7/30\n","1185/1185 [==============================] - 28s 24ms/step - loss: 0.2911 - accuracy: 0.9075 - val_loss: 0.5007 - val_accuracy: 0.8423\n","Epoch 8/30\n","1185/1185 [==============================] - 25s 21ms/step - loss: 0.2345 - accuracy: 0.9273 - val_loss: 0.4791 - val_accuracy: 0.8533\n","Epoch 9/30\n","1185/1185 [==============================] - 25s 21ms/step - loss: 0.1721 - accuracy: 0.9487 - val_loss: 0.4922 - val_accuracy: 0.8542\n","Epoch 10/30\n","1185/1185 [==============================] - 27s 23ms/step - loss: 0.1411 - accuracy: 0.9586 - val_loss: 0.5216 - val_accuracy: 0.8533\n","Epoch 11/30\n","1185/1185 [==============================] - 25s 21ms/step - loss: 0.1050 - accuracy: 0.9696 - val_loss: 0.5771 - val_accuracy: 0.8526\n","Epoch 12/30\n","1185/1185 [==============================] - 24s 20ms/step - loss: 0.0897 - accuracy: 0.9743 - val_loss: 0.5938 - val_accuracy: 0.8517\n","Epoch 13/30\n","1185/1185 [==============================] - 25s 21ms/step - loss: 0.0792 - accuracy: 0.9777 - val_loss: 0.6085 - val_accuracy: 0.8526\n","Epoch 14/30\n","1185/1185 [==============================] - 25s 21ms/step - loss: 0.0653 - accuracy: 0.9820 - val_loss: 0.6441 - val_accuracy: 0.8517\n","Epoch 15/30\n","1185/1185 [==============================] - 24s 20ms/step - loss: 0.0494 - accuracy: 0.9874 - val_loss: 0.6591 - val_accuracy: 0.8513\n","Epoch 1/5\n","1482/1482 [==============================] - 30s 20ms/step - loss: 0.1515 - accuracy: 0.9588\n","Epoch 2/5\n","1482/1482 [==============================] - 28s 19ms/step - loss: 0.0891 - accuracy: 0.9765\n","Epoch 3/5\n","1482/1482 [==============================] - 28s 19ms/step - loss: 0.0646 - accuracy: 0.9832\n","Epoch 4/5\n","1482/1482 [==============================] - 26s 18ms/step - loss: 0.0509 - accuracy: 0.9872\n","Epoch 5/5\n","1482/1482 [==============================] - 27s 19ms/step - loss: 0.0415 - accuracy: 0.9895\n","2605/2605 [==============================] - 22s 8ms/step\n"]}]},{"cell_type":"markdown","source":["Good. But I want to use f1 score as metric.\n","And change submission file name to 'submisson_nn_model2.csv'\n","\n","그래. f1 score를 model complie에 이용하는 방식으로, 코드 다시 짜줘"],"metadata":{"id":"FgxEWjKtE4hC"},"id":"FgxEWjKtE4hC"},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","# Custom F1 score metric function\n","def f1_metric(y_true, y_pred):\n","    true_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_true * y_pred, 0, 1)))\n","    possible_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_true, 0, 1)))\n","    predicted_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_pred, 0, 1)))\n","    precision = true_positives / (predicted_positives + tf.keras.backend.epsilon())\n","    recall = true_positives / (possible_positives + tf.keras.backend.epsilon())\n","    f1_val = 2 * (precision * recall) / (precision + recall + tf.keras.backend.epsilon())\n","    return f1_val\n","\n","# Load the data\n","train_data = pd.read_csv('train.csv')\n","test_data = pd.read_csv('test.csv')\n","\n","# Split the training data into training and validation sets\n","X_train, X_val, y_train, y_val = train_test_split(train_data['text'], train_data['label'], test_size=0.2, random_state=42)\n","\n","# Encode the labels\n","label_encoder = LabelEncoder()\n","y_train_encoded = label_encoder.fit_transform(y_train)\n","y_val_encoded = label_encoder.transform(y_val)\n","\n","# Tokenize the text data\n","max_features = 10000\n","max_len = 256\n","tokenizer = Tokenizer(num_words=max_features, oov_token='<OOV>')\n","tokenizer.fit_on_texts(X_train)\n","\n","X_train_sequences = tokenizer.texts_to_sequences(X_train)\n","X_val_sequences = tokenizer.texts_to_sequences(X_val)\n","X_train_padded = pad_sequences(X_train_sequences, maxlen=max_len, padding='post', truncating='post')\n","X_val_padded = pad_sequences(X_val_sequences, maxlen=max_len, padding='post', truncating='post')\n","\n","# Define the neural network model\n","model = Sequential([\n","    Embedding(max_features, 128, input_length=max_len),\n","    LSTM(64, return_sequences=True),\n","    Dropout(0.2),\n","    LSTM(32),\n","    Dense(8, activation='softmax')\n","])\n","\n","# Compile and train the model\n","model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy', f1_metric])\n","early_stop = EarlyStopping(monitor='val_loss', patience=10)\n","history = model.fit(X_train_padded, y_train_encoded, epochs=30, validation_data=(X_val_padded, y_val_encoded), callbacks=[early_stop])\n","\n","# Refit the model with the combined data\n","X_train_val = pd.concat([X_train, X_val])\n","y_train_val_encoded = label_encoder.transform(pd.concat([y_train, y_val]))\n","\n","X_train_val_sequences = tokenizer.texts_to_sequences(X_train_val)\n","X_train_val_padded = pad_sequences(X_train_val_sequences, maxlen=max_len, padding='post', truncating='post')\n","model.fit(X_train_val_padded, y_train_val_encoded, epochs=5)\n","\n","# Prepare the test data\n","test_sequences = tokenizer.texts_to_sequences(test_data['text'])\n","test_padded = pad_sequences(test_sequences, maxlen=max_len, padding='post', truncating='post')\n","\n","# Make predictions on the test set\n","test_predictions = np.argmax(model.predict(test_padded), axis=-1)\n","\n","# Decode the predicted labels\n","test_labels_pred = label_encoder.inverse_transform(test_predictions)\n","\n","# Create a submission file\n","submission = pd.DataFrame({'id': test_data['id'], 'label': test_labels_pred})\n","submission.to_csv('submission_nn_model2.csv', index=False)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RenysmlPAkfp","executionInfo":{"status":"ok","timestamp":1680156909226,"user_tz":-540,"elapsed":791815,"user":{"displayName":"지승영","userId":"07006377205744982370"}},"outputId":"0875d32e-4a66-4521-9c4f-97a15d51ae26"},"id":"RenysmlPAkfp","execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","1185/1185 [==============================] - 92s 74ms/step - loss: 1.2627 - accuracy: 0.4376 - f1_metric: 2.7133 - val_loss: 1.0581 - val_accuracy: 0.5194 - val_f1_metric: 1.8850\n","Epoch 2/30\n","1185/1185 [==============================] - 36s 31ms/step - loss: 0.9070 - accuracy: 0.5859 - f1_metric: 1.5278 - val_loss: 0.8332 - val_accuracy: 0.6670 - val_f1_metric: 1.3842\n","Epoch 3/30\n","1185/1185 [==============================] - 30s 26ms/step - loss: 0.6516 - accuracy: 0.7754 - f1_metric: 1.0741 - val_loss: 0.6087 - val_accuracy: 0.7863 - val_f1_metric: 1.0477\n","Epoch 4/30\n","1185/1185 [==============================] - 27s 23ms/step - loss: 0.4615 - accuracy: 0.8468 - f1_metric: 0.9758 - val_loss: 0.5074 - val_accuracy: 0.8300 - val_f1_metric: 0.9537\n","Epoch 5/30\n","1185/1185 [==============================] - 28s 24ms/step - loss: 0.3754 - accuracy: 0.8768 - f1_metric: 0.9587 - val_loss: 0.4712 - val_accuracy: 0.8405 - val_f1_metric: 0.9698\n","Epoch 6/30\n","1185/1185 [==============================] - 26s 22ms/step - loss: 0.3175 - accuracy: 0.8961 - f1_metric: 0.9411 - val_loss: 0.4654 - val_accuracy: 0.8463 - val_f1_metric: 0.9375\n","Epoch 7/30\n","1185/1185 [==============================] - 26s 22ms/step - loss: 0.2692 - accuracy: 0.9126 - f1_metric: 0.9286 - val_loss: 0.4794 - val_accuracy: 0.8484 - val_f1_metric: 0.9430\n","Epoch 8/30\n","1185/1185 [==============================] - 26s 22ms/step - loss: 0.2233 - accuracy: 0.9277 - f1_metric: 0.9240 - val_loss: 0.4755 - val_accuracy: 0.8550 - val_f1_metric: 0.9438\n","Epoch 9/30\n","1185/1185 [==============================] - 25s 21ms/step - loss: 0.1630 - accuracy: 0.9499 - f1_metric: 0.8933 - val_loss: 0.4698 - val_accuracy: 0.8569 - val_f1_metric: 0.9155\n","Epoch 10/30\n","1185/1185 [==============================] - 27s 23ms/step - loss: 0.1334 - accuracy: 0.9603 - f1_metric: 0.8788 - val_loss: 0.4827 - val_accuracy: 0.8654 - val_f1_metric: 0.9004\n","Epoch 11/30\n","1185/1185 [==============================] - 25s 21ms/step - loss: 0.1004 - accuracy: 0.9713 - f1_metric: 0.8642 - val_loss: 0.4857 - val_accuracy: 0.8639 - val_f1_metric: 0.8951\n","Epoch 12/30\n","1185/1185 [==============================] - 26s 22ms/step - loss: 0.0828 - accuracy: 0.9771 - f1_metric: 0.8554 - val_loss: 0.5604 - val_accuracy: 0.8566 - val_f1_metric: 0.8840\n","Epoch 13/30\n","1185/1185 [==============================] - 25s 21ms/step - loss: 0.0670 - accuracy: 0.9822 - f1_metric: 0.8477 - val_loss: 0.5728 - val_accuracy: 0.8591 - val_f1_metric: 0.8687\n","Epoch 14/30\n","1185/1185 [==============================] - 24s 20ms/step - loss: 0.0546 - accuracy: 0.9862 - f1_metric: 0.8402 - val_loss: 0.6189 - val_accuracy: 0.8582 - val_f1_metric: 0.8698\n","Epoch 15/30\n","1185/1185 [==============================] - 25s 21ms/step - loss: 0.0493 - accuracy: 0.9873 - f1_metric: 0.8396 - val_loss: 0.6033 - val_accuracy: 0.8615 - val_f1_metric: 0.8651\n","Epoch 16/30\n","1185/1185 [==============================] - 27s 23ms/step - loss: 0.0391 - accuracy: 0.9900 - f1_metric: 0.8348 - val_loss: 0.6688 - val_accuracy: 0.8600 - val_f1_metric: 0.8587\n","Epoch 1/5\n","1482/1482 [==============================] - 28s 19ms/step - loss: 0.1376 - accuracy: 0.9628 - f1_metric: 0.8574\n","Epoch 2/5\n","1482/1482 [==============================] - 28s 19ms/step - loss: 0.0792 - accuracy: 0.9804 - f1_metric: 0.8421\n","Epoch 3/5\n","1482/1482 [==============================] - 27s 18ms/step - loss: 0.0573 - accuracy: 0.9858 - f1_metric: 0.8382\n","Epoch 4/5\n","1482/1482 [==============================] - 30s 20ms/step - loss: 0.0438 - accuracy: 0.9891 - f1_metric: 0.8334\n","Epoch 5/5\n","1482/1482 [==============================] - 27s 18ms/step - loss: 0.0339 - accuracy: 0.9917 - f1_metric: 0.8301\n","2605/2605 [==============================] - 20s 7ms/step\n"]}]},{"cell_type":"markdown","source":["Oversampling using smote and train the model so that the ratio of all categories is more than 10%"],"metadata":{"id":"Sez2fS_OAkM6"},"id":"Sez2fS_OAkM6"},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n","from tensorflow.keras.callbacks import EarlyStopping\n","from imblearn.over_sampling import SMOTE\n","\n","# Custom F1 score metric function\n","def f1_metric(y_true, y_pred):\n","    true_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_true * y_pred, 0, 1)))\n","    possible_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_true, 0, 1)))\n","    predicted_positives = tf.keras.backend.sum(tf.keras.backend.round(tf.keras.backend.clip(y_pred, 0, 1)))\n","    precision = true_positives / (predicted_positives + tf.keras.backend.epsilon())\n","    recall = true_positives / (possible_positives + tf.keras.backend.epsilon())\n","    f1_val = 2 * (precision * recall) / (precision + recall + tf.keras.backend.epsilon())\n","    return f1_val\n","\n","# Load the data\n","train_data = pd.read_csv('train.csv')\n","test_data = pd.read_csv('test.csv')\n","\n","# Split the training data into training and validation sets\n","X_train, X_val, y_train, y_val = train_test_split(train_data['text'], train_data['label'], test_size=0.2, random_state=42)\n","\n","# Encode the labels\n","label_encoder = LabelEncoder()\n","y_train_encoded = label_encoder.fit_transform(y_train)\n","y_val_encoded = label_encoder.transform(y_val)\n","\n","# Tokenize the text data\n","max_features = 10000\n","max_len = 256\n","tokenizer = Tokenizer(num_words=max_features, oov_token='<OOV>')\n","tokenizer.fit_on_texts(X_train)\n","\n","X_train_sequences = tokenizer.texts_to_sequences(X_train)\n","X_val_sequences = tokenizer.texts_to_sequences(X_val)\n","X_train_padded = pad_sequences(X_train_sequences, maxlen=max_len, padding='post', truncating='post')\n","X_val_padded = pad_sequences(X_val_sequences, maxlen=max_len, padding='post', truncating='post')\n","\n","# Perform oversampling using SMOTE\n","smote = SMOTE(sampling_strategy='auto', random_state=42)\n","X_train_padded, y_train_encoded = smote.fit_resample(X_train_padded, y_train_encoded)\n","\n","# Define the neural network model\n","model = Sequential([\n","    Embedding(max_features, 128, input_length=max_len),\n","    LSTM(64, return_sequences=True),\n","    Dropout(0.2),\n","    LSTM(32),\n","    Dense(8, activation='softmax')\n","])\n","\n","# Compile and train the model\n","model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy', f1_metric])\n","early_stop = EarlyStopping(monitor='val_loss', patience=10)\n","history = model.fit(X_train_padded, y_train_encoded, epochs=30, validation_data=(X_val_padded, y_val_encoded), callbacks=[early_stop])\n","\n","# Refit the model with the combined data\n","X_train_val = pd.concat([X_train, X_val])\n","y_train_val_encoded = label_encoder.transform(pd.concat([y_train, y_val]))\n","\n","X_train_val_sequences = tokenizer.texts_to_sequences(X_train_val)\n","X_train_val_padded = pad_sequences(X_train_val_sequences, maxlen=max_len, padding='post', truncating='post')\n","\n","# Perform oversampling using SMOTE for the combined data\n","X_train_val_padded, y_train_val_encoded = smote.fit_resample(X_train_val_padded, y_train_val_encoded)\n","\n","# Refit the model with the combined data\n","model.fit(X_train_val_padded, y_train_val_encoded, epochs=5)\n","\n","# Prepare the test data\n","test_sequences = tokenizer.texts_to_sequences(test_data['text'])\n","test_padded = pad_sequences(test_sequences, maxlen=max_len, padding='post', truncating='post')\n","\n","# Make predictions on the test set\n","test_predictions = np.argmax(model.predict(test_padded), axis=-1)\n","\n","# Decode the predicted labels\n","test_labels_pred = label_encoder.inverse_transform(test_predictions)\n","\n","# Create a submission file\n","submission = pd.DataFrame({'id': test_data['id'], 'label': test_labels_pred})\n","submission.to_csv('submission_nn_model_oversample.csv', index=False)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aaSx-MYlKsEJ","executionInfo":{"status":"ok","timestamp":1680158871711,"user_tz":-540,"elapsed":1552297,"user":{"displayName":"지승영","userId":"07006377205744982370"}},"outputId":"919bed73-772a-4d6b-f490-384aea96d572"},"id":"aaSx-MYlKsEJ","execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","2827/2827 [==============================] - 137s 47ms/step - loss: 1.5109 - accuracy: 0.3967 - f1_metric: 4.5778 - val_loss: 1.3087 - val_accuracy: 0.4185 - val_f1_metric: 1.6692\n","Epoch 2/30\n","2827/2827 [==============================] - 64s 23ms/step - loss: 1.2333 - accuracy: 0.5136 - f1_metric: 2.8648 - val_loss: 1.0927 - val_accuracy: 0.5257 - val_f1_metric: 1.7257\n","Epoch 3/30\n","2827/2827 [==============================] - 58s 21ms/step - loss: 0.9819 - accuracy: 0.6406 - f1_metric: 2.0490 - val_loss: 0.6767 - val_accuracy: 0.7609 - val_f1_metric: 1.0971\n","Epoch 4/30\n","2827/2827 [==============================] - 58s 20ms/step - loss: 0.7941 - accuracy: 0.7135 - f1_metric: 1.8340 - val_loss: 0.5144 - val_accuracy: 0.8145 - val_f1_metric: 0.9993\n","Epoch 5/30\n","2827/2827 [==============================] - 57s 20ms/step - loss: 0.6603 - accuracy: 0.7649 - f1_metric: 1.6624 - val_loss: 0.4606 - val_accuracy: 0.8391 - val_f1_metric: 1.0275\n","Epoch 6/30\n","2827/2827 [==============================] - 56s 20ms/step - loss: 0.5596 - accuracy: 0.8039 - f1_metric: 1.5098 - val_loss: 0.4293 - val_accuracy: 0.8521 - val_f1_metric: 0.9698\n","Epoch 7/30\n","2827/2827 [==============================] - 54s 19ms/step - loss: 0.4759 - accuracy: 0.8361 - f1_metric: 1.3924 - val_loss: 0.4369 - val_accuracy: 0.8557 - val_f1_metric: 0.9482\n","Epoch 8/30\n","2827/2827 [==============================] - 54s 19ms/step - loss: 0.4049 - accuracy: 0.8614 - f1_metric: 1.3046 - val_loss: 0.4440 - val_accuracy: 0.8568 - val_f1_metric: 0.9340\n","Epoch 9/30\n","2827/2827 [==============================] - 55s 19ms/step - loss: 0.3398 - accuracy: 0.8852 - f1_metric: 1.2374 - val_loss: 0.5015 - val_accuracy: 0.8519 - val_f1_metric: 0.9064\n","Epoch 10/30\n","2827/2827 [==============================] - 54s 19ms/step - loss: 0.2837 - accuracy: 0.9042 - f1_metric: 1.1813 - val_loss: 0.5594 - val_accuracy: 0.8515 - val_f1_metric: 0.8918\n","Epoch 11/30\n","2827/2827 [==============================] - 54s 19ms/step - loss: 0.2375 - accuracy: 0.9208 - f1_metric: 1.1339 - val_loss: 0.5826 - val_accuracy: 0.8495 - val_f1_metric: 0.8851\n","Epoch 12/30\n","2827/2827 [==============================] - 56s 20ms/step - loss: 0.2003 - accuracy: 0.9345 - f1_metric: 1.0947 - val_loss: 0.6369 - val_accuracy: 0.8505 - val_f1_metric: 0.8732\n","Epoch 13/30\n","2827/2827 [==============================] - 55s 19ms/step - loss: 0.1671 - accuracy: 0.9459 - f1_metric: 1.0645 - val_loss: 0.7072 - val_accuracy: 0.8424 - val_f1_metric: 0.8723\n","Epoch 14/30\n","2827/2827 [==============================] - 55s 19ms/step - loss: 0.1410 - accuracy: 0.9543 - f1_metric: 1.0407 - val_loss: 0.7083 - val_accuracy: 0.8451 - val_f1_metric: 0.8735\n","Epoch 15/30\n","2827/2827 [==============================] - 55s 20ms/step - loss: 0.1197 - accuracy: 0.9620 - f1_metric: 1.0211 - val_loss: 0.7224 - val_accuracy: 0.8403 - val_f1_metric: 0.8741\n","Epoch 16/30\n","2827/2827 [==============================] - 54s 19ms/step - loss: 0.1046 - accuracy: 0.9672 - f1_metric: 1.0083 - val_loss: 0.7525 - val_accuracy: 0.8427 - val_f1_metric: 0.8676\n","Epoch 1/5\n","3537/3537 [==============================] - 67s 19ms/step - loss: 0.5747 - accuracy: 0.7997 - f1_metric: 1.5349\n","Epoch 2/5\n","3537/3537 [==============================] - 67s 19ms/step - loss: 0.4460 - accuracy: 0.8431 - f1_metric: 1.4191\n","Epoch 3/5\n","3537/3537 [==============================] - 67s 19ms/step - loss: 0.3557 - accuracy: 0.8759 - f1_metric: 1.2998\n","Epoch 4/5\n","3537/3537 [==============================] - 77s 22ms/step - loss: 0.2750 - accuracy: 0.9050 - f1_metric: 1.2003\n","Epoch 5/5\n","3537/3537 [==============================] - 67s 19ms/step - loss: 0.2068 - accuracy: 0.9294 - f1_metric: 1.1220\n","2605/2605 [==============================] - 22s 8ms/step\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"eD-6egMcLh0E"},"id":"eD-6egMcLh0E","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.4"},"colab":{"provenance":[]},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"d2235bc38f514c1ab3e6704c2826c609":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_942497cdbc6844039c99e844cbcb0427","IPY_MODEL_0ddaf4e1dca24553926e6ad03b06205e","IPY_MODEL_ab72dbfe3d36471383022d1936544705"],"layout":"IPY_MODEL_4ea1ac624a0e4c7586480652dfe82d4c"}},"942497cdbc6844039c99e844cbcb0427":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6a772397970a4c669113e43b4669d73d","placeholder":"​","style":"IPY_MODEL_cd7abff733aa4cdfa1d83443fd59db0f","value":"Downloading (…)okenizer_config.json: 100%"}},"0ddaf4e1dca24553926e6ad03b06205e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0d4b26fef0a441408ba66708047e2a26","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5005d5d2a6f348398f37be5424aac3f2","value":28}},"ab72dbfe3d36471383022d1936544705":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3f985e100a7a493b9af0d96093776520","placeholder":"​","style":"IPY_MODEL_986ea41221de4d269ffbd030fbce82f3","value":" 28.0/28.0 [00:00&lt;00:00, 234B/s]"}},"4ea1ac624a0e4c7586480652dfe82d4c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a772397970a4c669113e43b4669d73d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd7abff733aa4cdfa1d83443fd59db0f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0d4b26fef0a441408ba66708047e2a26":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5005d5d2a6f348398f37be5424aac3f2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3f985e100a7a493b9af0d96093776520":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"986ea41221de4d269ffbd030fbce82f3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"229a9b4f7f1b481f99e50050172d6949":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_15e0011cc9f540f2ba0217f50602291d","IPY_MODEL_750edc84afa74377bfc8ec3b59a42172","IPY_MODEL_a9fe05ffd7f242079cc398f78b47a7b6"],"layout":"IPY_MODEL_6b450b0338ba427181f64299f499e942"}},"15e0011cc9f540f2ba0217f50602291d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9f1cc170c7b84acea16123af070dae70","placeholder":"​","style":"IPY_MODEL_7c6f7269cdd3484799db806a536a767c","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"750edc84afa74377bfc8ec3b59a42172":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_09073d7273824416a3b72837c418365e","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cfc51cc99e6144e59546669724591f35","value":231508}},"a9fe05ffd7f242079cc398f78b47a7b6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f859a752856d45d48bc418fcc33cc658","placeholder":"​","style":"IPY_MODEL_c45b2f865c144155a12bb1f0fa873414","value":" 232k/232k [00:00&lt;00:00, 1.07MB/s]"}},"6b450b0338ba427181f64299f499e942":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f1cc170c7b84acea16123af070dae70":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c6f7269cdd3484799db806a536a767c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"09073d7273824416a3b72837c418365e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cfc51cc99e6144e59546669724591f35":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f859a752856d45d48bc418fcc33cc658":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c45b2f865c144155a12bb1f0fa873414":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a7ecf2d36f954f778d76e84bd3492ef6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cbf13baa3fad463e88e7fe637bc58ab9","IPY_MODEL_ff509959530f4d5dbeaeef2c4be82c1d","IPY_MODEL_0a079a37cb6241b798f211460e1e4a08"],"layout":"IPY_MODEL_a810086781a842ae9050b535c4c6f565"}},"cbf13baa3fad463e88e7fe637bc58ab9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3c10173d3b5c493d9833745ff25e0b48","placeholder":"​","style":"IPY_MODEL_ed13ab613f474b6da995d48629667b7e","value":"Downloading (…)/main/tokenizer.json: 100%"}},"ff509959530f4d5dbeaeef2c4be82c1d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5f168c47a21343a69b3f59cb0410d627","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2ba7be9513da4891bf4e4d8894ed3b9d","value":466062}},"0a079a37cb6241b798f211460e1e4a08":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ea918ef096304eae9f45244a63e433a2","placeholder":"​","style":"IPY_MODEL_a49ea5d722c64be68f1a8b5ac1368a9e","value":" 466k/466k [00:00&lt;00:00, 2.30MB/s]"}},"a810086781a842ae9050b535c4c6f565":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c10173d3b5c493d9833745ff25e0b48":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ed13ab613f474b6da995d48629667b7e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5f168c47a21343a69b3f59cb0410d627":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ba7be9513da4891bf4e4d8894ed3b9d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ea918ef096304eae9f45244a63e433a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a49ea5d722c64be68f1a8b5ac1368a9e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d54300b013b94d059a13780f1e0527e2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_75efa1e9c70448ef94b08fde1011a921","IPY_MODEL_c5d23b2f7b204ee9a00524e5c2d7b6f2","IPY_MODEL_1b221b7cf81b4fdeaa0c87336a66a1ae"],"layout":"IPY_MODEL_1f28e9cf30174dc691c41aa770045be7"}},"75efa1e9c70448ef94b08fde1011a921":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b1dd1e720c5142dabfbc62d5768945f7","placeholder":"​","style":"IPY_MODEL_f0897ec014524f3fa09f56c35e765329","value":"Downloading (…)lve/main/config.json: 100%"}},"c5d23b2f7b204ee9a00524e5c2d7b6f2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b4def8a04673453ca89e11e51b3ea2dd","max":483,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f7e3a3a2a1184df2bf3f85cb6dc6169d","value":483}},"1b221b7cf81b4fdeaa0c87336a66a1ae":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_98a0706280994a649129db105365fe81","placeholder":"​","style":"IPY_MODEL_924cc3e09e2a4697aa7fc60737416d9d","value":" 483/483 [00:00&lt;00:00, 6.24kB/s]"}},"1f28e9cf30174dc691c41aa770045be7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b1dd1e720c5142dabfbc62d5768945f7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f0897ec014524f3fa09f56c35e765329":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b4def8a04673453ca89e11e51b3ea2dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f7e3a3a2a1184df2bf3f85cb6dc6169d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"98a0706280994a649129db105365fe81":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"924cc3e09e2a4697aa7fc60737416d9d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}
>>>>>>> 89cd5b6b26708a3873dead06ca8c52f08e9d37ca
