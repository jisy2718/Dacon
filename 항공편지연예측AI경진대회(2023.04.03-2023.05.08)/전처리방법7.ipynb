{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28104,
     "status": "ok",
     "timestamp": 1682395271298,
     "user": {
      "displayName": "지승영",
      "userId": "07006377205744982370"
     },
     "user_tz": -540
    },
    "id": "-shg-k69keOm",
    "outputId": "8b8ee30a-2cdc-416b-b7cd-9341bd75000c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1682395300054,
     "user": {
      "displayName": "지승영",
      "userId": "07006377205744982370"
     },
     "user_tz": -540
    },
    "id": "WLDRz-uvkgjL",
    "outputId": "9f8c557a-ef34-4e78-f7dd-80e703cb5f9a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/drive/MyDrive/github/Dacon/항공편지연예측AI경진대회(2023.04.03-2023.05.08)'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('/content/drive/MyDrive/github/Dacon/항공편지연예측AI경진대회(2023.04.03-2023.05.08)')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LZ03gjSAWexe"
   },
   "source": [
    "## 1. 결측치처리\n",
    "**해당 노트북**\n",
    "+ 전처리방법2 + x결측치삭제 + vae 활용 + validation set 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "pO82uV5UhWZo"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import gc\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "seed_everything(42) # Seed 고정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9midQA40kaZ7"
   },
   "source": [
    "### 1.1. 전처리방법2 데이터 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2232,
     "status": "ok",
     "timestamp": 1682398048619,
     "user": {
      "displayName": "지승영",
      "userId": "07006377205744982370"
     },
     "user_tz": -540
    },
    "id": "R1yJwPUBkaZ9",
    "outputId": "565b249d-cfde-414b-cb1f-f48c303bda5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000, 19)\n",
      "Not_Delayed    210001\n",
      "Delayed         45000\n",
      "Name: Delay, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_parquet('./data/train_preprocess_2.parquet')\n",
    "# test = pd.read_parquet('./test.parquet')\n",
    "test = pd.read_parquet('./data/test_preprocess_2.parquet')\n",
    "sample_submission = pd.read_csv('sample_submission.csv', index_col = 0)\n",
    "\n",
    "print(train.shape)\n",
    "print(train.Delay.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3FjWnl6WuVXp"
   },
   "source": [
    "### 1.2. 남은 결측치 처리 - 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2073,
     "status": "ok",
     "timestamp": 1682398467992,
     "user": {
      "displayName": "지승영",
      "userId": "07006377205744982370"
     },
     "user_tz": -540
    },
    "id": "-_OkLK6bsdCe",
    "outputId": "e5d0d96b-93ce-48e3-a637-9385d0102530"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID                               0\n",
      "Month                            0\n",
      "Day_of_Month                     0\n",
      "Estimated_Departure_Time         0\n",
      "Estimated_Arrival_Time           0\n",
      "Cancelled                        0\n",
      "Diverted                         0\n",
      "Origin_Airport                   0\n",
      "Origin_Airport_ID                0\n",
      "Origin_State                     0\n",
      "Destination_Airport              0\n",
      "Destination_Airport_ID           0\n",
      "Destination_State                0\n",
      "Distance                         0\n",
      "Airline                          0\n",
      "Carrier_Code(IATA)               0\n",
      "Carrier_ID(DOT)                  0\n",
      "Tail_Number                      0\n",
      "Delay                       520399\n",
      "dtype: int64\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# print(train.isnull().sum())\n",
    "# print(train.dropna().shape)\n",
    "# print(train.dropna().isnull().sum())\n",
    "train = train.dropna(subset=['Estimated_Departure_Time','Estimated_Arrival_Time','Carrier_Code(IATA)','Airline','Carrier_ID(DOT)'])\n",
    "print(train.isnull().sum())\n",
    "\n",
    "\n",
    "# 레이블(Delay)을 제외한 결측값이 존재하는 변수들을 unknown으로 대체합니다.\n",
    "NaN_col = ['Origin_State','Destination_State','Airline','Estimated_Departure_Time', 'Estimated_Arrival_Time','Carrier_Code(IATA)','Carrier_ID(DOT)']\n",
    "\n",
    "for col in NaN_col:\n",
    "    # mode = train[col].mode()[0]\n",
    "    # train[col] = train[col].fillna(mode)\n",
    "    \n",
    "    if col in test.columns:\n",
    "        test[col] = test[col].fillna('Unknown')\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. label & unlabel split  / label_train & label_validation split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1배치 데이터 흐름\n",
    "1. vae에는 X_train_labeled와 X_unlabeled를 각각 onehot으로 만들어서 합쳐서 넣어주기\n",
    "2. classifier에는 X_train_labeled를 onehot으로 만든 것 넣어주기\n",
    "\n",
    "\n",
    "#### 필요한 것\n",
    "1. labeled와 unlabeled 나누기\n",
    "2. labeled에서 train과 validation 분리하기\n",
    "3. X_train_labeld & X_unlabeled 를 이용한 onehot encoding\n",
    "4. 전체 데이터에 onehot 적용하면 데이터 크기 너무 커지므로, 배치로 처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_3676\\4037750646.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y_labeled['Delay'] = y_labeled['Delay'].apply(lambda x : change_cate2num[x])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178176, 17) (520399, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneHotEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "OneHotEncoder()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. labeled & unlabeld split\n",
    "train_labeled , train_unlabeled = train[train['Delay'].notnull()], train[train['Delay'].isnull()]\n",
    "\n",
    "X_labeled, y_labeled = train_labeled.drop(['ID','Delay'], axis=1), train_labeled[['Delay']]\n",
    "change_cate2num = {'Not_Delayed':0, \"Delayed\":1}\n",
    "y_labeled['Delay'] = y_labeled['Delay'].apply(lambda x : change_cate2num[x])\n",
    "X_unlabeled = train_unlabeled.drop(['ID','Delay'], axis=1)\n",
    "\n",
    "print(X_labeled.shape, X_unlabeled.shape)\n",
    "\n",
    "\n",
    "# 2. train_labeled & val_labeled split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_labeled, X_val_labeled, y_train_labeled, y_val_labeled = train_test_split(X_labeled, y_labeled, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# 3. 데이터 정리 & onehotencoding\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "cate_cols = ['Month', 'Day_of_Month', 'Cancelled', 'Diverted', 'Origin_Airport',\n",
    "       'Origin_Airport_ID', 'Origin_State', 'Destination_Airport',\n",
    "       'Destination_Airport_ID', 'Destination_State', 'Airline',\n",
    "       'Carrier_Code(IATA)', 'Carrier_ID(DOT)', 'Tail_Number']\n",
    "\n",
    "\n",
    "# Airport 2개 삭제함\n",
    "cate_cols = ['Month', 'Day_of_Month', 'Cancelled', 'Diverted', \n",
    "       'Origin_Airport_ID', 'Origin_State', \n",
    "       'Destination_Airport_ID', 'Destination_State', 'Airline',\n",
    "       'Carrier_Code(IATA)', 'Carrier_ID(DOT)', 'Tail_Number']\n",
    "\n",
    "numeric_cols = ['Estimated_Departure_Time','Estimated_Arrival_Time','Distance']\n",
    "\n",
    "## 3.1. VAE 훈련에 쓸 데이터 : X_train_labeled, X_unlabeled\n",
    "### 3.1.1. 데이터 정리\n",
    "X_vae_train = pd.concat([X_train_labeled, X_unlabeled])\n",
    "X_vae_train_cate = X_vae_train[cate_cols]\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "encoder.fit(X_vae_train_cate)\n",
    "\n",
    "\n",
    "# X_vae_train_numeric = X_vae_train[numeric_cols].astype(np.float32)\n",
    "\n",
    "### 3.1.2. 범주형 변수를 원-핫 인코딩으로 변환\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import torch\n",
    "\n",
    "class Flight_labeled(Dataset): \n",
    "    def __init__(self, X_train_labeled, y_train_labeled, encoder):\n",
    "        # 1. 데이터 받아오기\n",
    "        self.X_train_labeled = X_train_labeled\n",
    "        self.y_train_labeled =  y_train_labeled\n",
    "        \n",
    "        self.cate_cols = ['Month', 'Day_of_Month', 'Cancelled', 'Diverted', 'Origin_Airport_ID', \\\n",
    "                          'Origin_State', 'Destination_Airport_ID', 'Destination_State', 'Airline',\\\n",
    "                          'Carrier_Code(IATA)', 'Carrier_ID(DOT)', 'Tail_Number']\n",
    "\n",
    "        self.numeric_cols = ['Estimated_Departure_Time','Estimated_Arrival_Time','Distance']\n",
    "\n",
    "        \n",
    "        \n",
    "    # 사용 가능한 데이터 개수 return\n",
    "    def __len__(self):\n",
    "        return len(self.X_train_labeled)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        # onehot encoding 후, tensor로 반환하기\n",
    "        # 1. category는 onehot으로 변환하고, numeric은 category onehot 뒤에 붙이기\n",
    "        X_sample_category = self.X_train_labeled[self.cate_cols].iloc[i,:].to_frame().T\n",
    "#         print('1: ', X_sample_category.dtype, X_sample_category.shape)\n",
    "        \n",
    "        X_sample_category = encoder.transform(X_sample_category)\n",
    "#         print('2: ', X_sample_category.dtype, X_sample_category.shape)\n",
    "        \n",
    "        X_sample_category = X_sample_category.toarray()  # 추가된 코드: X_sample_category를 2차원 배열로 변환 : 희소행렬로 반환되는 onehot encoding 결과를, 일반적인 Numpy 배열로 변환해줌\n",
    "#         print('3: ', X_sample_category.dtype, X_sample_category.shape)\n",
    "        \n",
    "        X_sample_numeric = np.array(self.X_train_labeled[self.numeric_cols].iloc[i,:]).reshape(1,-1)\n",
    "#         print('4: ', X_sample_numeric.dtype, X_sample_numeric.shape)\n",
    "        \n",
    "        X_sample = np.hstack([X_sample_category,X_sample_numeric])\n",
    "#         print('5: ', X_sample.dtype, X_sample.shape)\n",
    "        \n",
    "        # 2. 텐서로 변환하기\n",
    "        X_sample = torch.tensor(X_sample, dtype=torch.float32)\n",
    "        y_sample = torch.tensor(self.y_train_labeled.iloc[i,:].values, dtype=torch.float32)\n",
    "        \n",
    "\n",
    "        return X_sample, y_sample\n",
    "    \n",
    "\n",
    "class Flight_unlabeled(Dataset):\n",
    "    def __init__(self, X_unlabeled, encoder):\n",
    "        self.X_unlabeled =  X_unlabeled\n",
    "\n",
    "        \n",
    "        \n",
    "    # 사용 가능한 데이터 개수 return\n",
    "    def __len__(self):\n",
    "        return len(self.X_unlabeled)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        # onehot encoding 후, tensor로 반환하기\n",
    "        # 1. category는 onehot으로 변환하고, numeric은 category onehot 뒤에 붙이기\n",
    "        X_sample_category = self.X_unlabeled[self.cate_cols].iloc[i,:].to_frame().T\n",
    "#         print('1: ', X_sample_category.dtype, X_sample_category.shape)\n",
    "        \n",
    "        X_sample_category = encoder.transform(X_sample_category)\n",
    "#         print('2: ', X_sample_category.dtype, X_sample_category.shape)\n",
    "        \n",
    "        X_sample_category = X_sample_category.toarray()  # 추가된 코드: X_sample_category를 2차원 배열로 변환 : 희소행렬로 반환되는 onehot encoding 결과를, 일반적인 Numpy 배열로 변환해줌\n",
    "#         print('3: ', X_sample_category.dtype, X_sample_category.shape)\n",
    "        \n",
    "        X_sample_numeric = np.array(self.X_train_labeled[self.numeric_cols].iloc[i,:]).reshape(1,-1)\n",
    "#         print('4: ', X_sample_numeric.dtype, X_sample_numeric.shape)\n",
    "        \n",
    "        X_sample = np.hstack([X_sample_category,X_sample_numeric])\n",
    "#         print('5: ', X_sample.dtype, X_sample.shape)\n",
    "        \n",
    "        # 2. 텐서로 변환하기\n",
    "        X_sample = torch.tensor(X_sample, dtype=torch.float32)\n",
    "        return X_sample\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142540 520399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                 | 1/1114 [00:01<33:06,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data batch shape: torch.Size([128, 1, 7377])\n",
      "Label batch shape: torch.Size([128, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|▏                                                                                | 2/1114 [00:03<33:16,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data batch shape: torch.Size([128, 1, 7377])\n",
      "Label batch shape: torch.Size([128, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|▏                                                                                | 3/1114 [00:05<33:14,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data batch shape: torch.Size([128, 1, 7377])\n",
      "Label batch shape: torch.Size([128, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|▎                                                                                | 4/1114 [00:07<33:30,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data batch shape: torch.Size([128, 1, 7377])\n",
      "Label batch shape: torch.Size([128, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|▎                                                                                | 5/1114 [00:09<33:27,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data batch shape: torch.Size([128, 1, 7377])\n",
      "Label batch shape: torch.Size([128, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▍                                                                                | 6/1114 [00:10<33:12,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data batch shape: torch.Size([128, 1, 7377])\n",
      "Label batch shape: torch.Size([128, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▌                                                                                | 7/1114 [00:12<33:01,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data batch shape: torch.Size([128, 1, 7377])\n",
      "Label batch shape: torch.Size([128, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▌                                                                                | 8/1114 [00:14<33:16,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data batch shape: torch.Size([128, 1, 7377])\n",
      "Label batch shape: torch.Size([128, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▋                                                                                | 9/1114 [00:16<33:16,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data batch shape: torch.Size([128, 1, 7377])\n",
      "Label batch shape: torch.Size([128, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▋                                                                               | 10/1114 [00:18<33:17,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data batch shape: torch.Size([128, 1, 7377])\n",
      "Label batch shape: torch.Size([128, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▊                                                                               | 11/1114 [00:19<33:02,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data batch shape: torch.Size([128, 1, 7377])\n",
      "Label batch shape: torch.Size([128, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▊                                                                               | 12/1114 [00:21<32:59,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data batch shape: torch.Size([128, 1, 7377])\n",
      "Label batch shape: torch.Size([128, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▉                                                                               | 13/1114 [00:23<33:04,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data batch shape: torch.Size([128, 1, 7377])\n",
      "Label batch shape: torch.Size([128, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|█                                                                               | 14/1114 [00:25<33:08,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data batch shape: torch.Size([128, 1, 7377])\n",
      "Label batch shape: torch.Size([128, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|█                                                                               | 15/1114 [00:27<33:08,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data batch shape: torch.Size([128, 1, 7377])\n",
      "Label batch shape: torch.Size([128, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█                                                                               | 15/1114 [00:28<34:41,  1.89s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 13\u001b[0m\n\u001b[0;32m      9\u001b[0m unlabel_loader \u001b[38;5;241m=\u001b[39m DataLoader(unlabel_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m)\n\u001b[0;32m     12\u001b[0m iterator \u001b[38;5;241m=\u001b[39m tqdm\u001b[38;5;241m.\u001b[39mtqdm(label_loader)\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data, label \u001b[38;5;129;01min\u001b[39;00m iterator:\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m#     print(len(data), label.sum())\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData batch shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, data\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLabel batch shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, label\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tqdm\\std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1192\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1195\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1196\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1197\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1198\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    633\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 634\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    638\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    676\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    677\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 678\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    679\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    680\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[55], line 34\u001b[0m, in \u001b[0;36mFlight_labeled.__getitem__\u001b[1;34m(self, i)\u001b[0m\n\u001b[0;32m     31\u001b[0m         X_sample_category \u001b[38;5;241m=\u001b[39m encoder\u001b[38;5;241m.\u001b[39mtransform(X_sample_category)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m#         print('2: ', X_sample_category.dtype, X_sample_category.shape)\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m         X_sample_category \u001b[38;5;241m=\u001b[39m \u001b[43mX_sample_category\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 추가된 코드: X_sample_category를 2차원 배열로 변환 : 희소행렬로 반환되는 onehot encoding 결과를, 일반적인 Numpy 배열로 변환해줌\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m#         print('3: ', X_sample_category.dtype, X_sample_category.shape)\u001b[39;00m\n\u001b[0;32m     37\u001b[0m         X_sample_numeric \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_train_labeled[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumeric_cols]\u001b[38;5;241m.\u001b[39miloc[i,:])\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\_compressed.py:1051\u001b[0m, in \u001b[0;36m_cs_matrix.toarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m order \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1050\u001b[0m     order \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_swap(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcf\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m-> 1051\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_toarray_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1052\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (out\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mc_contiguous \u001b[38;5;129;01mor\u001b[39;00m out\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mf_contiguous):\n\u001b[0;32m   1053\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOutput array must be C or F contiguous\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\_base.py:1298\u001b[0m, in \u001b[0;36mspmatrix._process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[0;32m   1297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.utils.data.dataloader import DataLoader\n",
    "import tqdm\n",
    "\n",
    "label_dataset = Flight_labeled(X_train_labeled,y_train_labeled, encoder)\n",
    "unlabel_dataset = Flight_unlabeled(X_unlabeled, encoder)\n",
    "print(len(label_dataset),len(unlabel_dataset))\n",
    "\n",
    "label_loader = DataLoader(label_dataset, batch_size=128)\n",
    "unlabel_loader = DataLoader(unlabel_dataset, batch_size=32)\n",
    "\n",
    "\n",
    "iterator = tqdm.tqdm(label_loader)\n",
    "for data, label in iterator:\n",
    "#     print(len(data), label.sum())\n",
    "    print(\"Data batch shape:\", data.shape)\n",
    "    print(\"Label batch shape:\", label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12], dtype=int64),\n",
       " array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31],\n",
       "       dtype=int64),\n",
       " array([0], dtype=int64),\n",
       " array([0], dtype=int64),\n",
       " array([10135, 10136, 10140, 10141, 10146, 10154, 10155, 10157, 10158,\n",
       "        10165, 10170, 10185, 10208, 10245, 10257, 10268, 10275, 10279,\n",
       "        10299, 10333, 10361, 10372, 10397, 10408, 10409, 10423, 10431,\n",
       "        10434, 10466, 10469, 10529, 10551, 10558, 10561, 10562, 10577,\n",
       "        10581, 10599, 10620, 10627, 10631, 10643, 10666, 10676, 10685,\n",
       "        10693, 10713, 10721, 10728, 10731, 10732, 10739, 10747, 10754,\n",
       "        10779, 10781, 10785, 10792, 10800, 10821, 10849, 10868, 10874,\n",
       "        10918, 10926, 10967, 10980, 10990, 10994, 11003, 11013, 11027,\n",
       "        11042, 11049, 11057, 11066, 11067, 11076, 11092, 11097, 11109,\n",
       "        11111, 11122, 11140, 11146, 11150, 11193, 11203, 11233, 11252,\n",
       "        11259, 11267, 11274, 11278, 11292, 11298, 11308, 11315, 11336,\n",
       "        11337, 11413, 11415, 11423, 11433, 11445, 11447, 11468, 11470,\n",
       "        11471, 11481, 11503, 11525, 11537, 11540, 11577, 11587, 11603,\n",
       "        11612, 11617, 11618, 11624, 11630, 11637, 11638, 11641, 11648,\n",
       "        11695, 11697, 11699, 11721, 11775, 11778, 11823, 11865, 11867,\n",
       "        11884, 11898, 11905, 11921, 11953, 11973, 11977, 11980, 11982,\n",
       "        11986, 11995, 11996, 11997, 12003, 12007, 12012, 12016, 12094,\n",
       "        12119, 12124, 12129, 12156, 12173, 12177, 12191, 12197, 12206,\n",
       "        12217, 12223, 12244, 12250, 12255, 12264, 12265, 12266, 12278,\n",
       "        12280, 12323, 12335, 12339, 12343, 12365, 12389, 12391, 12397,\n",
       "        12402, 12441, 12448, 12451, 12478, 12492, 12511, 12519, 12523,\n",
       "        12544, 12758, 12819, 12884, 12888, 12889, 12891, 12892, 12896,\n",
       "        12898, 12899, 12902, 12915, 12917, 12945, 12951, 12953, 12954,\n",
       "        12982, 12992, 13029, 13034, 13061, 13076, 13121, 13127, 13139,\n",
       "        13158, 13184, 13198, 13204, 13230, 13232, 13241, 13244, 13256,\n",
       "        13264, 13277, 13290, 13296, 13303, 13342, 13344, 13347, 13360,\n",
       "        13367, 13377, 13388, 13422, 13433, 13459, 13476, 13485, 13486,\n",
       "        13487, 13495, 13502, 13541, 13577, 13795, 13796, 13829, 13830,\n",
       "        13832, 13851, 13871, 13873, 13891, 13930, 13931, 13933, 13964,\n",
       "        13970, 13983, 14004, 14006, 14025, 14027, 14057, 14082, 14092,\n",
       "        14098, 14100, 14107, 14108, 14109, 14112, 14113, 14120, 14122,\n",
       "        14150, 14193, 14222, 14231, 14237, 14252, 14254, 14256, 14259,\n",
       "        14262, 14288, 14303, 14307, 14314, 14321, 14457, 14487, 14489,\n",
       "        14492, 14512, 14520, 14524, 14543, 14570, 14574, 14576, 14582,\n",
       "        14588, 14633, 14635, 14674, 14679, 14683, 14685, 14689, 14696,\n",
       "        14698, 14704, 14709, 14711, 14716, 14730, 14747, 14761, 14771,\n",
       "        14783, 14794, 14802, 14814, 14828, 14831, 14842, 14843, 14869,\n",
       "        14877, 14893, 14905, 14908, 14952, 14955, 14960, 14986, 15008,\n",
       "        15016, 15023, 15024, 15027, 15041, 15048, 15070, 15074, 15096,\n",
       "        15249, 15295, 15304, 15323, 15356, 15370, 15376, 15380, 15389,\n",
       "        15401, 15411, 15412, 15454, 15582, 15607, 15624, 15841, 15897,\n",
       "        15919, 15991, 16101, 16218, 16869], dtype=int64),\n",
       " array(['Alabama', 'Alaska', 'Arizona', 'Arkansas', 'California',\n",
       "        'Colorado', 'Connecticut', 'Florida', 'Georgia', 'Hawaii', 'Idaho',\n",
       "        'Illinois', 'Indiana', 'Iowa', 'Kansas', 'Kentucky', 'Louisiana',\n",
       "        'Maine', 'Maryland', 'Massachusetts', 'Michigan', 'Minnesota',\n",
       "        'Mississippi', 'Missouri', 'Montana', 'Nebraska', 'Nevada',\n",
       "        'New Hampshire', 'New Jersey', 'New Mexico', 'New York',\n",
       "        'North Carolina', 'North Dakota', 'Ohio', 'Oklahoma', 'Oregon',\n",
       "        'Pennsylvania', 'Puerto Rico', 'Rhode Island', 'South Carolina',\n",
       "        'South Dakota', 'Tennessee', 'Texas',\n",
       "        'U.S. Pacific Trust Territories and Possessions',\n",
       "        'U.S. Virgin Islands', 'Utah', 'Vermont', 'Virginia', 'Washington',\n",
       "        'West Virginia', 'Wisconsin', 'Wyoming'], dtype=object),\n",
       " array([10135, 10136, 10140, 10141, 10146, 10154, 10155, 10157, 10158,\n",
       "        10165, 10170, 10185, 10208, 10245, 10257, 10268, 10275, 10279,\n",
       "        10299, 10333, 10361, 10372, 10397, 10408, 10409, 10423, 10431,\n",
       "        10434, 10466, 10469, 10529, 10551, 10558, 10561, 10562, 10577,\n",
       "        10581, 10599, 10620, 10627, 10631, 10643, 10666, 10676, 10685,\n",
       "        10693, 10713, 10721, 10728, 10731, 10732, 10739, 10747, 10754,\n",
       "        10779, 10781, 10785, 10792, 10800, 10821, 10849, 10868, 10874,\n",
       "        10918, 10926, 10967, 10980, 10990, 10994, 11003, 11013, 11027,\n",
       "        11042, 11049, 11057, 11066, 11067, 11076, 11092, 11097, 11109,\n",
       "        11111, 11122, 11140, 11146, 11150, 11193, 11203, 11233, 11252,\n",
       "        11259, 11267, 11274, 11278, 11292, 11298, 11308, 11315, 11336,\n",
       "        11337, 11413, 11415, 11423, 11433, 11445, 11447, 11468, 11470,\n",
       "        11471, 11481, 11503, 11525, 11537, 11540, 11577, 11587, 11603,\n",
       "        11612, 11617, 11618, 11624, 11630, 11637, 11638, 11641, 11648,\n",
       "        11695, 11697, 11699, 11721, 11775, 11778, 11823, 11865, 11867,\n",
       "        11884, 11898, 11905, 11921, 11953, 11973, 11977, 11980, 11982,\n",
       "        11986, 11995, 11996, 11997, 12003, 12007, 12012, 12016, 12094,\n",
       "        12119, 12124, 12129, 12156, 12173, 12177, 12191, 12197, 12206,\n",
       "        12217, 12223, 12244, 12250, 12255, 12264, 12265, 12266, 12278,\n",
       "        12280, 12323, 12335, 12339, 12343, 12365, 12389, 12391, 12397,\n",
       "        12402, 12441, 12448, 12451, 12478, 12492, 12511, 12519, 12523,\n",
       "        12544, 12758, 12819, 12884, 12888, 12889, 12891, 12892, 12896,\n",
       "        12898, 12899, 12902, 12915, 12917, 12945, 12951, 12953, 12954,\n",
       "        12982, 12992, 13029, 13034, 13061, 13076, 13121, 13127, 13139,\n",
       "        13158, 13184, 13198, 13204, 13230, 13232, 13241, 13244, 13256,\n",
       "        13264, 13277, 13290, 13296, 13303, 13342, 13344, 13347, 13360,\n",
       "        13367, 13377, 13388, 13422, 13433, 13459, 13476, 13485, 13486,\n",
       "        13487, 13495, 13502, 13541, 13577, 13795, 13796, 13829, 13830,\n",
       "        13832, 13851, 13871, 13873, 13891, 13930, 13931, 13933, 13964,\n",
       "        13970, 13983, 14004, 14006, 14025, 14027, 14057, 14082, 14092,\n",
       "        14098, 14100, 14107, 14108, 14109, 14112, 14113, 14120, 14122,\n",
       "        14150, 14193, 14222, 14231, 14237, 14252, 14254, 14256, 14259,\n",
       "        14262, 14288, 14303, 14307, 14314, 14321, 14457, 14487, 14489,\n",
       "        14492, 14512, 14520, 14524, 14543, 14570, 14574, 14576, 14582,\n",
       "        14588, 14633, 14635, 14674, 14679, 14683, 14685, 14689, 14696,\n",
       "        14698, 14704, 14709, 14711, 14716, 14730, 14747, 14761, 14771,\n",
       "        14783, 14794, 14802, 14814, 14828, 14831, 14842, 14843, 14869,\n",
       "        14877, 14893, 14905, 14908, 14952, 14955, 14960, 14986, 15008,\n",
       "        15016, 15023, 15024, 15027, 15041, 15048, 15070, 15074, 15096,\n",
       "        15249, 15295, 15304, 15323, 15356, 15370, 15376, 15380, 15389,\n",
       "        15401, 15411, 15412, 15454, 15582, 15607, 15624, 15841, 15897,\n",
       "        15919, 15991, 16101, 16133, 16218, 16869], dtype=int64),\n",
       " array(['Alabama', 'Alaska', 'Arizona', 'Arkansas', 'California',\n",
       "        'Colorado', 'Connecticut', 'Florida', 'Georgia', 'Hawaii', 'Idaho',\n",
       "        'Illinois', 'Indiana', 'Iowa', 'Kansas', 'Kentucky', 'Louisiana',\n",
       "        'Maine', 'Maryland', 'Massachusetts', 'Michigan', 'Minnesota',\n",
       "        'Mississippi', 'Missouri', 'Montana', 'Nebraska', 'Nevada',\n",
       "        'New Hampshire', 'New Jersey', 'New Mexico', 'New York',\n",
       "        'North Carolina', 'North Dakota', 'Ohio', 'Oklahoma', 'Oregon',\n",
       "        'Pennsylvania', 'Puerto Rico', 'Rhode Island', 'South Carolina',\n",
       "        'South Dakota', 'Tennessee', 'Texas',\n",
       "        'U.S. Pacific Trust Territories and Possessions',\n",
       "        'U.S. Virgin Islands', 'Utah', 'Vermont', 'Virginia', 'Washington',\n",
       "        'West Virginia', 'Wisconsin', 'Wyoming'], dtype=object),\n",
       " array(['Air Wisconsin Airlines Corp', 'Alaska Airlines Inc.',\n",
       "        'Allegiant Air', 'American Airlines Inc.', 'Cape Air',\n",
       "        'Capital Cargo International', 'Comair Inc.',\n",
       "        'Commutair Aka Champlain Enterprises, Inc.', 'Compass Airlines',\n",
       "        'Delta Air Lines Inc.', 'Empire Airlines Inc.',\n",
       "        'Endeavor Air Inc.', 'Envoy Air', 'ExpressJet Airlines Inc.',\n",
       "        'Frontier Airlines Inc.',\n",
       "        'GoJet Airlines, LLC d/b/a United Express',\n",
       "        'Hawaiian Airlines Inc.', 'Horizon Air', 'JetBlue Airways',\n",
       "        'Mesa Airlines Inc.', 'Peninsula Airways Inc.',\n",
       "        'Republic Airlines', 'SkyWest Airlines Inc.',\n",
       "        'Southwest Airlines Co.', 'Spirit Air Lines',\n",
       "        'Trans States Airlines', 'United Air Lines Inc.', 'Virgin America'],\n",
       "       dtype=object),\n",
       " array(['AA', 'AS', 'B6', 'DL', 'F9', 'G4', 'HA', 'NK', 'UA', 'VX', 'WN'],\n",
       "       dtype=object),\n",
       " array([19393., 19687., 19690., 19790., 19805., 19930., 19977., 20046.,\n",
       "        20225., 20237., 20253., 20263., 20304., 20363., 20366., 20368.,\n",
       "        20378., 20397., 20398., 20409., 20416., 20427., 20436., 20445.,\n",
       "        20452., 20500., 21167., 21171.]),\n",
       " array(['215NV', '216NV', '217NV', ..., 'N999DN', 'N999JB', 'N999JQ'],\n",
       "       dtype=object)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encoder.categories_\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 아래는 아직 작성 안한 부분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from torch.utils.data.dataset import Dataset\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# class Flight(Dataset): # 1. 클래스 선언\n",
    "#     def __init__(self):\n",
    "#         # 1. 데이터 읽기 & label, unlabel 나누기\n",
    "#         self.data = train\n",
    "        \n",
    "#         self.train_labeled , self.train_unlabeled = self.train[train['Delay'].notnull()], self.train[train['Delay'].isnull()]\n",
    "        \n",
    "#         self.X_labeled, self.y_labeled = self.train_labeled.drop(['ID','Delay'], axis=1), self.train_labeled['Delay']\n",
    "        \n",
    "#         ## y값 0,1로 바꾸기\n",
    "#         change_cate2num = {'Not_Delayed':0, \"Delayed\":1}\n",
    "#         y_labeled['Delay'] = y_labeled['Delay'].apply(lambda x : change_cate2num[x])\n",
    "        \n",
    "#         self.X_unlabeled = self.train_unlabeled.drop(['ID','Delay'], axis=1)\n",
    "\n",
    "#         print(self.X_labeled.shape, self.X_unlabeld.shape)\n",
    "\n",
    "\n",
    "#         # 2. train_labeled & val_labeled split\n",
    "#         self.X_train_labeled, self.X_val_labeled, self.y_train_labeled, self.y_val_labeled = train_test_split(X_labeled, y_labeled, test_size=0.2, random_state=42)\n",
    "\n",
    "        \n",
    "        \n",
    "#         # 3. 데이터 정리 & onehotencoding\n",
    "#         cate_cols = ['Month', 'Day_of_Month', 'Cancelled', 'Diverted', 'Origin_Airport',\n",
    "#                'Origin_Airport_ID', 'Origin_State', 'Destination_Airport',\n",
    "#                'Destination_Airport_ID', 'Destination_State', 'Airline',\n",
    "#                'Carrier_Code(IATA)', 'Carrier_ID(DOT)', 'Tail_Number']\n",
    "\n",
    "#         numeric_cols = ['Estimated_Departure_Time','Estimated_Arrival_Time','Distance']\n",
    "\n",
    "#         ## 3.1. VAE 훈련에 쓸 데이터 : X_train_labeled, X_unlabeled\n",
    "#         ### 3.1.1. 데이터 정리\n",
    "#         self.X_vae_train = pd.concat([self.X_train_labeled, self.X_unlabeled])\n",
    "#         self.X_vae_train_cate = self.X_vae_train[cate_cols]\n",
    "#         self.X_vae_train_numeric = self.X_vae_train[numeric_cols].astype(np.float32)\n",
    "\n",
    "#         ### 3.1.2. 범주형 변수를 원-핫 인코딩으로 변환\n",
    "#         encoder = OneHotEncoder()\n",
    "#         self.X_vae_train_onehot_categorical = encoder.fit_transform(self.X_vae_train_cate).toarray()\n",
    "#         self.X_vae_train_encoded = np.hstack((self.X_vae_train_onehot_categorical, self.X_vae_train_numeric.values))\n",
    "\n",
    "        \n",
    "#         ## 3.2. classifier에 쓸 데이터 : X_train_labeled, y_train_labeled\n",
    "#         self.X_classifier_train_cate = self.X_train_labeled[cate_cols]\n",
    "#         self.X_classifier_train_numeric = self.X_train_labeled[numeric_cols].astype(np.float32)\n",
    "#         self.X_classifier_onehot_cate = encoder.fit_transform(self.X_classifier_train_cate).toarray()\n",
    "#         self.X_classifier_train_encoded = np.hstack((self.X_classifier_onehot_cate, self.X_classifier_train_numeric.values))\n",
    "        \n",
    "#         ## 3.3. 성능 평가에 쓸 데이터 : X_val_labeled, y_val_labeled\n",
    "        \n",
    "        \n",
    "#     # 사용 가능한 데이터 개수 return\n",
    "#     def __len__(self):\n",
    "#         return\n",
    "    \n",
    "#     def __getitem__(self, i):\n",
    "#         return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Delay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Not_Delayed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Not_Delayed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Delayed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Not_Delayed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Not_Delayed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999950</th>\n",
       "      <td>Not_Delayed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999955</th>\n",
       "      <td>Delayed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999963</th>\n",
       "      <td>Delayed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999985</th>\n",
       "      <td>Not_Delayed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999992</th>\n",
       "      <td>Not_Delayed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178176 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Delay\n",
       "6       Not_Delayed\n",
       "8       Not_Delayed\n",
       "10          Delayed\n",
       "12      Not_Delayed\n",
       "13      Not_Delayed\n",
       "...             ...\n",
       "999950  Not_Delayed\n",
       "999955      Delayed\n",
       "999963      Delayed\n",
       "999985  Not_Delayed\n",
       "999992  Not_Delayed\n",
       "\n",
       "[178176 rows x 1 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178176, 17) (520399, 18)\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 40.1 GiB for an array with shape (662939, 8123) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 32\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m### 3.1.2. 범주형 변수를 원-핫 인코딩으로 변환\u001b[39;00m\n\u001b[0;32m     31\u001b[0m encoder \u001b[38;5;241m=\u001b[39m OneHotEncoder()\n\u001b[1;32m---> 32\u001b[0m X_vae_train_onehot_categorical \u001b[38;5;241m=\u001b[39m \u001b[43mencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_vae_train_cate\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m X_vae_train_encoded \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhstack((X_vae_train_onehot_categorical, X_vae_train_numeric\u001b[38;5;241m.\u001b[39mvalues))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\_compressed.py:1051\u001b[0m, in \u001b[0;36m_cs_matrix.toarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m order \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1050\u001b[0m     order \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_swap(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcf\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m-> 1051\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_toarray_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1052\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (out\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mc_contiguous \u001b[38;5;129;01mor\u001b[39;00m out\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mf_contiguous):\n\u001b[0;32m   1053\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOutput array must be C or F contiguous\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\_base.py:1298\u001b[0m, in \u001b[0;36mspmatrix._process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[0;32m   1297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 40.1 GiB for an array with shape (662939, 8123) and data type float64"
     ]
    }
   ],
   "source": [
    "# # 1. labeled & unlabeld split\n",
    "# train_labeled , train_unlabeled = train[train['Delay'].notnull()], train[train['Delay'].isnull()]\n",
    "\n",
    "# X_labeled, y_labeled = train_labeled.drop(['ID','Delay'], axis=1), train_labeled['Delay']\n",
    "# change_cate2num = {'Not_Delayed':0, \"Delayed\":1}\n",
    "# y_labeled['Delay'] = y_labeled['Delay'].apply(lambda x : change_cate2num[x])\n",
    "# X_unlabeled = train_unlabeled.drop(['ID','Delay'], axis=1)\n",
    "\n",
    "# print(X_labeled.shape, X_unlabeld.shape)\n",
    "\n",
    "\n",
    "# # 2. train_labeled & val_labeled split\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train_labeled, X_val_labeled, y_train_labeled, y_val_labeled = train_test_split(X_labeled, y_labeled, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# # 3. 데이터 정리 & onehotencoding\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# cate_cols = ['Month', 'Day_of_Month', 'Cancelled', 'Diverted', 'Origin_Airport',\n",
    "#        'Origin_Airport_ID', 'Origin_State', 'Destination_Airport',\n",
    "#        'Destination_Airport_ID', 'Destination_State', 'Airline',\n",
    "#        'Carrier_Code(IATA)', 'Carrier_ID(DOT)', 'Tail_Number']\n",
    "\n",
    "# numeric_cols = ['Estimated_Departure_Time','Estimated_Arrival_Time','Distance']\n",
    "\n",
    "# ## 3.1. VAE 훈련에 쓸 데이터 : X_train_labeled, X_unlabeled\n",
    "# ### 3.1.1. 데이터 정리\n",
    "# X_vae_train = pd.concat([X_train_labeled, X_unlabeled])\n",
    "# X_vae_train_cate = X_vae_train[cate_cols]\n",
    "# X_vae_train_numeric = X_vae_train[numeric_cols].astype(np.float32)\n",
    "\n",
    "# ### 3.1.2. 범주형 변수를 원-핫 인코딩으로 변환\n",
    "# encoder = OneHotEncoder()\n",
    "# X_vae_train_onehot_categorical = encoder.fit_transform(X_vae_train_cate).toarray()\n",
    "# X_vae_train_encoded = np.hstack((X_vae_train_onehot_categorical, X_vae_train_numeric.values))\n",
    "\n",
    "# ## 3.2. classifier에 쓸 데이터 : X_train_labeled, y_train_labeled\n",
    "\n",
    "\n",
    "# ## 3.3. 성능 평가에 쓸 데이터 : X_val_labeled, y_val_labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tSpy0yeMpkYc"
   },
   "source": [
    "## 2. 준지도학습진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TJwR7tZ0qtxd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PkrYr_Q2kaa-"
   },
   "source": [
    "### 전처리방법7 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RrfZWy4skaa_",
    "outputId": "4ab0d8cf-c561-46a7-99ee-d94fa4379fb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "몇 번째 전처리 방법인지 정수-정수를 입력하세요 : 4\n"
     ]
    }
   ],
   "source": [
    "save_idx = input('몇 번째 전처리 방법인지 정수-정수를 입력하세요 : ')\n",
    "train_save_name = 'train_preprocess_' + save_idx\n",
    "test_save_name = 'test_preprocess_' + save_idx\n",
    "train.to_parquet(f'./data/{train_save_name}.parquet')\n",
    "test.to_parquet(f'./data/{test_save_name}.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xjmnbSg0kabA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
